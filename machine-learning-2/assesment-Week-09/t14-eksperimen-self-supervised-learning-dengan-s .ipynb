{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":109264,"sourceType":"datasetVersion","datasetId":56828}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\n\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom torchvision.transforms import transforms\n\nimport yaml\n\nimport logging\nimport sys\nimport csv\nimport torch\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\n\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-02T14:13:00.588777Z","iopub.execute_input":"2025-08-02T14:13:00.589018Z","iopub.status.idle":"2025-08-02T14:13:09.098714Z","shell.execute_reply.started":"2025-08-02T14:13:00.588996Z","shell.execute_reply":"2025-08-02T14:13:09.098196Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\ntorch.manual_seed(0)\nnp.random.seed(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T14:13:09.099350Z","iopub.execute_input":"2025-08-02T14:13:09.099702Z","iopub.status.idle":"2025-08-02T14:13:09.109542Z","shell.execute_reply.started":"2025-08-02T14:13:09.099678Z","shell.execute_reply":"2025-08-02T14:13:09.108872Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"\nclass GaussianBlur(object):\n    \"\"\"blur a single image on CPU\"\"\"\n    def __init__(self, kernel_size):\n        radias = kernel_size // 2\n        kernel_size = radias * 2 + 1\n        self.blur_h = nn.Conv2d(3, 3, kernel_size=(kernel_size, 1),\n                                stride=1, padding=0, bias=False, groups=3)\n        self.blur_v = nn.Conv2d(3, 3, kernel_size=(1, kernel_size),\n                                stride=1, padding=0, bias=False, groups=3)\n        self.k = kernel_size\n        self.r = radias\n\n        self.blur = nn.Sequential(\n            nn.ReflectionPad2d(radias),\n            self.blur_h,\n            self.blur_v\n        )\n\n        self.pil_to_tensor = transforms.ToTensor()\n        self.tensor_to_pil = transforms.ToPILImage()\n\n    def __call__(self, img):\n        img = self.pil_to_tensor(img).unsqueeze(0)\n\n        sigma = np.random.uniform(0.1, 2.0)\n        x = np.arange(-self.r, self.r + 1)\n        x = np.exp(-np.power(x, 2) / (2 * sigma * sigma))\n        x = x / x.sum()\n        x = torch.from_numpy(x).view(1, -1).repeat(3, 1)\n\n        self.blur_h.weight.data.copy_(x.view(3, 1, self.k, 1))\n        self.blur_v.weight.data.copy_(x.view(3, 1, 1, self.k))\n\n        with torch.no_grad():\n            img = self.blur(img)\n            img = img.squeeze()\n\n        img = self.tensor_to_pil(img)\n\n        return img\n        \ndef save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, 'model_best.pth.tar')\n\n\ndef save_config_file(model_checkpoints_folder, args):\n    if not os.path.exists(model_checkpoints_folder):\n        os.makedirs(model_checkpoints_folder)\n        with open(os.path.join(model_checkpoints_folder, 'config.yml'), 'w') as outfile:\n            yaml.dump(args, outfile, default_flow_style=False)\n\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T14:13:09.110926Z","iopub.execute_input":"2025-08-02T14:13:09.111117Z","iopub.status.idle":"2025-08-02T14:13:09.139589Z","shell.execute_reply.started":"2025-08-02T14:13:09.111102Z","shell.execute_reply":"2025-08-02T14:13:09.138929Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# SimCLR","metadata":{}},{"cell_type":"code","source":"\nclass SimCLR(object):\n\n    def __init__(self, *args, **kwargs):\n        self.args = kwargs['args']\n        self.model = kwargs['model'].to(self.args.device)\n        self.optimizer = kwargs['optimizer']\n        self.scheduler = kwargs['scheduler']\n        # self.writer = SummaryWriter()\n        # logging.basicConfig(filename=os.path.join(self.writer.log_dir, 'training.log'), level=logging.DEBUG)\n        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.device)\n\n        os.makedirs(self.args.log_dir, exist_ok=True)\n        logging.basicConfig(filename=os.path.join(self.args.log_dir, 'training.log'),\n                            level=logging.INFO,\n                            format='%(asctime)s - %(levelname)s - %(message)s')\n\n        self.csv_log_path = os.path.join(self.args.log_dir, 'metrics.csv')\n        with open(self.csv_log_path, mode='w', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow(['step', 'loss', 'acc_top1', 'acc_top5', 'learning_rate'])\n\n        \n\n    def info_nce_loss(self, features):\n\n        labels = torch.cat([torch.arange(self.args.batch_size) for i in range(self.args.n_views)], dim=0)\n        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n        labels = labels.to(self.args.device)\n\n        features = F.normalize(features, dim=1)\n\n        similarity_matrix = torch.matmul(features, features.T)\n        # assert similarity_matrix.shape == (\n        #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n        # assert similarity_matrix.shape == labels.shape\n\n        # discard the main diagonal from both: labels and similarities matrix\n        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args.device)\n        labels = labels[~mask].view(labels.shape[0], -1)\n        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n        # assert similarity_matrix.shape == labels.shape\n\n        # select and combine multiple positives\n        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n\n        # select only the negatives the negatives\n        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n\n        logits = torch.cat([positives, negatives], dim=1)\n        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args.device)\n\n        logits = logits / self.args.temperature\n        return logits, labels\n\n    def train(self, train_loader):\n\n        scaler = GradScaler(enabled=self.args.fp16_precision)\n\n        # save config file\n        # save_config_file(self.writer.log_dir, self.args)\n\n        n_iter = 0\n        best_top1 = 0.0  \n        logging.info(f\"Start SimCLR training for {self.args.epochs} epochs.\")\n\n        for epoch_counter in range(self.args.epochs):\n            for images, _ in tqdm(train_loader):\n                images = torch.cat(images, dim=0)\n\n                images = images.to(self.args.device)\n\n                with autocast(enabled=self.args.fp16_precision):\n                    features = self.model(images)\n                    logits, labels = self.info_nce_loss(features)\n                    loss = self.criterion(logits, labels)\n\n                self.optimizer.zero_grad()\n\n                scaler.scale(loss).backward()\n\n                scaler.step(self.optimizer)\n                scaler.update()\n\n                if n_iter % self.args.log_every_n_steps == 0:\n                    top1, top5 = accuracy(logits, labels, topk=(1, 5))\n                    lr = self.scheduler.get_last_lr()[0]\n\n                    print(f\"[Epoch {epoch_counter+1}] Step {n_iter}: Loss={loss:.4f}, Top1={top1[0]:.2f}%, Top5={top5[0]:.2f}%, LR={lr:.6f}\")\n\n\n                    # File log\n                    with open(self.csv_log_path, mode='a', newline='') as f:\n                        writer = csv.writer(f)\n                        writer.writerow([n_iter, loss.item(), top1[0].item(), top5[0].item(), lr])\n\n                    if top1[0].item() > best_top1:\n                        best_top1 = top1[0].item()\n                        best_ckpt_path = os.path.join(self.args.log_dir, 'checkpoint_best.pth')\n                        save_checkpoint({\n                            'epoch': epoch_counter + 1,\n                            'arch': self.args.arch,\n                            'state_dict': self.model.state_dict(),\n                            'optimizer': self.optimizer.state_dict(),\n                            'best_top1': best_top1\n                        }, is_best=True, filename=best_ckpt_path)\n                        logging.info(f\"New best model saved with Top1={best_top1:.2f}% at epoch {epoch_counter+1}, step {n_iter}\")\n\n                    \n\n                n_iter += 1\n\n            # warmup for the first 10 epochs\n            if epoch_counter >= 10:\n                self.scheduler.step()\n            logging.debug(f\"Epoch: {epoch_counter}\\tLoss: {loss}\\tTop1 accuracy: {top1[0]}\")\n\n        logging.info(\"Training has finished.\")\n        # save model checkpoints\n        checkpoint_name = os.path.join(self.args.log_dir, f'checkpoint_{self.args.epochs:04d}.pth.tar')\n        \n        save_checkpoint({\n            'epoch': self.args.epochs,\n            'arch': self.args.arch,\n            'state_dict': self.model.state_dict(),\n            'optimizer': self.optimizer.state_dict(),\n        }, is_best=False, filename=checkpoint_name)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T14:13:09.140187Z","iopub.execute_input":"2025-08-02T14:13:09.140425Z","iopub.status.idle":"2025-08-02T14:13:09.160973Z","shell.execute_reply.started":"2025-08-02T14:13:09.140404Z","shell.execute_reply":"2025-08-02T14:13:09.160422Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Exceptions","metadata":{}},{"cell_type":"code","source":"class BaseSimCLRException(Exception):\n    \"\"\"Base exception\"\"\"\n\n\nclass InvalidBackboneError(BaseSimCLRException):\n    \"\"\"Raised when the choice of backbone Convnet is invalid.\"\"\"\n\n\nclass InvalidDatasetSelection(BaseSimCLRException):\n    \"\"\"Raised when the choice of dataset is invalid.\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T14:13:09.161659Z","iopub.execute_input":"2025-08-02T14:13:09.161811Z","iopub.status.idle":"2025-08-02T14:13:09.180373Z","shell.execute_reply.started":"2025-08-02T14:13:09.161798Z","shell.execute_reply":"2025-08-02T14:13:09.179782Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class ContrastiveLearningViewGenerator(object):\n    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n\n    def __init__(self, base_transform, n_views=2):\n        self.base_transform = base_transform\n        self.n_views = n_views\n\n    def __call__(self, x):\n        return [self.base_transform(x) for i in range(self.n_views)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T14:13:09.181372Z","iopub.execute_input":"2025-08-02T14:13:09.181610Z","iopub.status.idle":"2025-08-02T14:13:09.199706Z","shell.execute_reply.started":"2025-08-02T14:13:09.181589Z","shell.execute_reply":"2025-08-02T14:13:09.199166Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from torchvision.transforms import transforms\nfrom torchvision import transforms, datasets\n\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import Dataset\nfrom PIL import Image\n\n\nclass ContrastiveLearningDataset:\n    def __init__(self, root_folder):\n        self.root_folder = root_folder\n\n    @staticmethod\n    def get_simclr_pipeline_transform(size, s=1):\n        \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n        color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n        data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=size),\n                                              transforms.RandomHorizontalFlip(),\n                                              transforms.RandomApply([color_jitter], p=0.8),\n                                              transforms.RandomGrayscale(p=0.2),\n                                              GaussianBlur(kernel_size=int(0.1 * size)),\n                                              transforms.ToTensor()])\n        return data_transforms\n\n    def get_dataset(self, name, n_views):\n        valid_datasets = {\n                        'cifar10': lambda: datasets.CIFAR10(self.root_folder, train=True,\n                                                          transform=ContrastiveLearningViewGenerator(\n                                                              self.get_simclr_pipeline_transform(32),\n                                                              n_views),\n                                                          download=True),\n                        'stl10': lambda: datasets.STL10(self.root_folder, split='unlabeled',\n                                                      transform=ContrastiveLearningViewGenerator(\n                                                          self.get_simclr_pipeline_transform(96),\n                                                          n_views),\n                                                      download=True),\n                        'tinyimagenet' : lambda: ImageFolder(\n                            root=os.path.join(self.root_folder, 'tiny-imagenet-200', 'train'),\n                            transform=ContrastiveLearningViewGenerator(\n                                self.get_simclr_pipeline_transform(64),  \n                                n_views))\n                        }\n\n        try:\n            dataset_fn = valid_datasets[name]\n        except KeyError:\n            raise InvalidDatasetSelection()\n        else:\n            return dataset_fn()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T14:13:09.200418Z","iopub.execute_input":"2025-08-02T14:13:09.200638Z","iopub.status.idle":"2025-08-02T14:13:09.215211Z","shell.execute_reply.started":"2025-08-02T14:13:09.200617Z","shell.execute_reply":"2025-08-02T14:13:09.214568Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Encoder Model\n ","metadata":{}},{"cell_type":"code","source":"\nimport torchvision.models as models\n\n\n\nclass ResNetSimCLR(nn.Module):\n\n    def __init__(self, base_model, out_dim):\n        super(ResNetSimCLR, self).__init__()\n        self.resnet_dict = {\"resnet18\": models.resnet18(weights=None, num_classes=out_dim),\n                            \"resnet50\": models.resnet50(weights=None, num_classes=out_dim)}\n\n        self.backbone = self._get_basemodel(base_model)\n        dim_mlp = self.backbone.fc.in_features\n\n        # add mlp projection head dengan arsitektur yang lebih kompleks\n        self.backbone.fc = nn.Sequential(\n            nn.Linear(dim_mlp, 256),  # Lapisan pertama\n            nn.ReLU(),\n            nn.Linear(256, 128),      # Lapisan kedua\n            nn.ReLU(),\n            nn.Linear(128, out_dim)   # Lapisan terakhir, pastikan out_dim sesuai\n        )\n\n    def _get_basemodel(self, model_name):\n        try:\n            model = self.resnet_dict[model_name]\n        except KeyError:\n            raise InvalidBackboneError(\n                \"Invalid backbone architecture. Check the config file and pass one of: resnet18 or resnet50\")\n        else:\n            return model\n\n    def forward(self, x):\n        return self.backbone(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T14:13:09.215783Z","iopub.execute_input":"2025-08-02T14:13:09.216374Z","iopub.status.idle":"2025-08-02T14:13:09.234299Z","shell.execute_reply.started":"2025-08-02T14:13:09.216356Z","shell.execute_reply":"2025-08-02T14:13:09.233637Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"code","source":"\nmodel_names = sorted(name for name in models.__dict__\n                     if name.islower() and not name.startswith(\"__\")\n                     and callable(models.__dict__[name]))\nprint(model_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T14:13:09.235847Z","iopub.execute_input":"2025-08-02T14:13:09.236047Z","iopub.status.idle":"2025-08-02T14:13:09.253920Z","shell.execute_reply.started":"2025-08-02T14:13:09.236031Z","shell.execute_reply":"2025-08-02T14:13:09.253400Z"}},"outputs":[{"name":"stdout","text":"['alexnet', 'convnext_base', 'convnext_large', 'convnext_small', 'convnext_tiny', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'efficientnet_v2_l', 'efficientnet_v2_m', 'efficientnet_v2_s', 'get_model', 'get_model_builder', 'get_model_weights', 'get_weight', 'googlenet', 'inception_v3', 'list_models', 'maxvit_t', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'mobilenet_v3_large', 'mobilenet_v3_small', 'regnet_x_16gf', 'regnet_x_1_6gf', 'regnet_x_32gf', 'regnet_x_3_2gf', 'regnet_x_400mf', 'regnet_x_800mf', 'regnet_x_8gf', 'regnet_y_128gf', 'regnet_y_16gf', 'regnet_y_1_6gf', 'regnet_y_32gf', 'regnet_y_3_2gf', 'regnet_y_400mf', 'regnet_y_800mf', 'regnet_y_8gf', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext101_64x4d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'swin_b', 'swin_s', 'swin_t', 'swin_v2_b', 'swin_v2_s', 'swin_v2_t', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'vit_b_16', 'vit_b_32', 'vit_h_14', 'vit_l_16', 'vit_l_32', 'wide_resnet101_2', 'wide_resnet50_2']\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from types import SimpleNamespace\nimport torch.backends.cudnn as cudnn\n\nargs = SimpleNamespace()\nargs.device = torch.device('cuda')\nargs.data = '/kaggle/input/tiny-imagenet/tiny-imagenet-200'\ncudnn.deterministic = True\ncudnn.benchmark = True\nargs.dataset_name = 'tinyimagenet'\nargs.n_views = 2\nargs.batch_size = 512\nargs.out_dim = 128\nargs.lr = 0.0003\nargs.weight_decay = 1e-4\nargs.arch = 'resnet50'\nargs.workers = 2\nargs.gpu_index = 0\nargs.log_dir = '/kaggle/working/logs/simclr'\nargs.fp16_precision = True\nargs.epochs = 50\nargs.temperature = 0.1\nargs.seed = 1\nargs.log_every_n_steps = 100\ndataset = ContrastiveLearningDataset(args.data)\n\ntrain_dataset = dataset.get_dataset(args.dataset_name, args.n_views)\n\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=args.batch_size, shuffle=True,\n    num_workers=args.workers, pin_memory=True, drop_last=True)\n\nmodel = ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)\n\noptimizer = torch.optim.Adam(model.parameters(), args.lr, weight_decay=args.weight_decay)\n\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0,\n                                                       last_epoch=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T14:13:09.254659Z","iopub.execute_input":"2025-08-02T14:13:09.255254Z","iopub.status.idle":"2025-08-02T14:16:58.211324Z","shell.execute_reply.started":"2025-08-02T14:13:09.255233Z","shell.execute_reply":"2025-08-02T14:16:58.210715Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"with torch.cuda.device(args.gpu_index):\n    simclr = SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n    simclr.train(train_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T14:16:58.212034Z","iopub.execute_input":"2025-08-02T14:16:58.212292Z","iopub.status.idle":"2025-08-02T18:36:12.790736Z","shell.execute_reply.started":"2025-08-02T14:16:58.212268Z","shell.execute_reply":"2025-08-02T18:36:12.789945Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/943341053.py:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler(enabled=self.args.fp16_precision)\n  0%|          | 0/195 [00:00<?, ?it/s]/tmp/ipykernel_36/943341053.py:72: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=self.args.fp16_precision):\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] Step 0: Loss=7.0970, Top1=0.20%, Top5=0.68%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 101/195 [04:16<03:15,  2.09s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] Step 100: Loss=6.7830, Top1=0.20%, Top5=5.18%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [07:55<00:00,  2.44s/it]\n  3%|▎         | 5/195 [00:09<05:29,  1.74s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] Step 200: Loss=6.4703, Top1=1.07%, Top5=3.71%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 105/195 [02:32<02:13,  1.48s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] Step 300: Loss=6.2577, Top1=1.56%, Top5=7.52%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:46<00:00,  1.47s/it]\n  5%|▌         | 10/195 [00:15<04:07,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] Step 400: Loss=5.9287, Top1=3.91%, Top5=12.70%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▋    | 110/195 [02:42<01:51,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] Step 500: Loss=5.7519, Top1=7.81%, Top5=16.50%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:57<00:00,  1.52s/it]\n  8%|▊         | 15/195 [00:24<04:54,  1.64s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] Step 600: Loss=5.5461, Top1=8.30%, Top5=20.61%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 115/195 [02:51<02:14,  1.68s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] Step 700: Loss=5.0728, Top1=14.55%, Top5=29.59%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:53<00:00,  1.51s/it]\n 10%|█         | 20/195 [00:29<03:39,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] Step 800: Loss=4.8190, Top1=19.82%, Top5=34.67%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 120/195 [02:52<01:38,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] Step 900: Loss=4.6746, Top1=22.36%, Top5=37.70%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:44<00:00,  1.46s/it]\n 13%|█▎        | 25/195 [00:38<04:32,  1.60s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 6] Step 1000: Loss=4.3815, Top1=24.41%, Top5=42.77%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 125/195 [03:04<01:56,  1.66s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 6] Step 1100: Loss=4.2808, Top1=27.44%, Top5=46.19%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:51<00:00,  1.49s/it]\n 15%|█▌        | 30/195 [00:47<03:41,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 7] Step 1200: Loss=4.1779, Top1=29.49%, Top5=46.78%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 130/195 [03:20<01:30,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 7] Step 1300: Loss=3.6079, Top1=37.40%, Top5=56.45%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:00<00:00,  1.54s/it]\n 18%|█▊        | 35/195 [00:52<04:12,  1.58s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 8] Step 1400: Loss=3.8325, Top1=38.57%, Top5=52.25%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 70%|██████▉   | 136/195 [03:22<01:17,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 8] Step 1500: Loss=3.8102, Top1=37.60%, Top5=53.61%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:50<00:00,  1.49s/it]\n 21%|██        | 40/195 [01:00<03:21,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 9] Step 1600: Loss=3.7088, Top1=40.92%, Top5=56.15%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 141/195 [03:26<01:17,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 9] Step 1700: Loss=3.7164, Top1=38.96%, Top5=52.83%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:45<00:00,  1.46s/it]\n 23%|██▎       | 45/195 [01:06<03:49,  1.53s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 10] Step 1800: Loss=3.5421, Top1=41.80%, Top5=57.23%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 145/195 [03:30<01:19,  1.58s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 10] Step 1900: Loss=3.4362, Top1=43.07%, Top5=60.35%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:43<00:00,  1.45s/it]\n 26%|██▌       | 51/195 [01:15<03:49,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 11] Step 2000: Loss=3.4484, Top1=41.80%, Top5=58.79%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 151/195 [03:39<01:12,  1.65s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 11] Step 2100: Loss=3.5363, Top1=39.65%, Top5=58.59%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:43<00:00,  1.46s/it]\n 28%|██▊       | 55/195 [01:21<03:39,  1.57s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 12] Step 2200: Loss=3.0501, Top1=49.90%, Top5=67.19%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 156/195 [03:49<00:51,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 12] Step 2300: Loss=3.3069, Top1=44.04%, Top5=61.72%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:50<00:00,  1.49s/it]\n 31%|███▏      | 61/195 [01:34<03:42,  1.66s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 13] Step 2400: Loss=3.2724, Top1=49.51%, Top5=63.48%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 161/195 [03:59<00:49,  1.45s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 13] Step 2500: Loss=3.3609, Top1=46.39%, Top5=62.21%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:49<00:00,  1.49s/it]\n 34%|███▍      | 66/195 [01:36<02:45,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 14] Step 2600: Loss=3.2852, Top1=46.09%, Top5=63.18%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 166/195 [04:03<00:37,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 14] Step 2700: Loss=3.1383, Top1=48.44%, Top5=66.11%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:46<00:00,  1.47s/it]\n 36%|███▌      | 70/195 [01:41<02:39,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 15] Step 2800: Loss=3.1459, Top1=50.00%, Top5=65.92%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 171/195 [04:08<00:37,  1.58s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 15] Step 2900: Loss=3.1967, Top1=49.90%, Top5=64.16%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:43<00:00,  1.45s/it]\n 38%|███▊      | 75/195 [01:49<03:10,  1.58s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 16] Step 3000: Loss=3.1687, Top1=51.76%, Top5=65.62%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 176/195 [04:15<00:25,  1.32s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 16] Step 3100: Loss=3.0543, Top1=51.76%, Top5=66.31%, LR=0.000300\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:44<00:00,  1.46s/it]\n 41%|████      | 80/195 [02:05<02:44,  1.43s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 17] Step 3200: Loss=3.0183, Top1=53.52%, Top5=66.99%, LR=0.000299\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 181/195 [04:47<00:24,  1.73s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 17] Step 3300: Loss=3.0415, Top1=52.25%, Top5=66.89%, LR=0.000299\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:08<00:00,  1.58s/it]\n 44%|████▎     | 85/195 [02:09<02:59,  1.63s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 18] Step 3400: Loss=2.8860, Top1=54.10%, Top5=67.87%, LR=0.000299\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 186/195 [04:44<00:16,  1.80s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 18] Step 3500: Loss=3.0575, Top1=49.12%, Top5=66.41%, LR=0.000299\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:00<00:00,  1.54s/it]\n 47%|████▋     | 91/195 [02:30<02:49,  1.63s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 19] Step 3600: Loss=2.9197, Top1=52.44%, Top5=68.65%, LR=0.000299\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 191/195 [05:17<00:07,  1.81s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 19] Step 3700: Loss=3.1187, Top1=51.46%, Top5=65.72%, LR=0.000299\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:23<00:00,  1.66s/it]\n 49%|████▉     | 96/195 [02:18<02:11,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 20] Step 3800: Loss=2.9289, Top1=53.52%, Top5=68.16%, LR=0.000298\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:50<00:00,  1.49s/it]\n  0%|          | 0/195 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 21] Step 3900: Loss=2.8950, Top1=54.98%, Top5=68.85%, LR=0.000298\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████▏    | 100/195 [02:23<02:04,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 21] Step 4000: Loss=2.8273, Top1=57.71%, Top5=71.29%, LR=0.000298\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:38<00:00,  1.43s/it]\n  3%|▎         | 6/195 [00:09<04:13,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 22] Step 4100: Loss=2.9003, Top1=54.39%, Top5=69.14%, LR=0.000298\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 105/195 [02:32<02:14,  1.50s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 22] Step 4200: Loss=2.7110, Top1=58.50%, Top5=73.44%, LR=0.000298\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:40<00:00,  1.44s/it]\n  6%|▌         | 11/195 [00:17<05:00,  1.63s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 23] Step 4300: Loss=2.9139, Top1=52.54%, Top5=70.21%, LR=0.000297\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▋    | 110/195 [02:37<01:49,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 23] Step 4400: Loss=2.6458, Top1=59.77%, Top5=73.54%, LR=0.000297\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:39<00:00,  1.43s/it]\n  8%|▊         | 16/195 [00:23<03:38,  1.22s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 24] Step 4500: Loss=2.8879, Top1=54.88%, Top5=69.73%, LR=0.000297\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 116/195 [02:44<01:40,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 24] Step 4600: Loss=2.6539, Top1=58.01%, Top5=74.51%, LR=0.000297\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:38<00:00,  1.43s/it]\n 11%|█         | 21/195 [00:32<04:42,  1.62s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 25] Step 4700: Loss=2.7829, Top1=57.62%, Top5=71.19%, LR=0.000296\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 121/195 [02:58<02:02,  1.66s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 25] Step 4800: Loss=2.8018, Top1=55.08%, Top5=70.31%, LR=0.000296\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:50<00:00,  1.49s/it]\n 13%|█▎        | 26/195 [00:38<03:32,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 26] Step 4900: Loss=2.6875, Top1=59.18%, Top5=75.59%, LR=0.000296\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▍   | 126/195 [03:06<01:33,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 26] Step 5000: Loss=2.7807, Top1=58.20%, Top5=73.54%, LR=0.000296\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:49<00:00,  1.48s/it]\n 16%|█▌        | 31/195 [00:46<04:29,  1.64s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 27] Step 5100: Loss=2.7770, Top1=57.81%, Top5=71.29%, LR=0.000295\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 131/195 [03:10<01:40,  1.56s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 27] Step 5200: Loss=2.6608, Top1=58.79%, Top5=73.54%, LR=0.000295\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:43<00:00,  1.45s/it]\n 18%|█▊        | 36/195 [00:52<03:22,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 28] Step 5300: Loss=2.6634, Top1=57.42%, Top5=71.97%, LR=0.000294\n","output_type":"stream"},{"name":"stderr","text":" 70%|██████▉   | 136/195 [03:16<01:15,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 28] Step 5400: Loss=2.6782, Top1=57.52%, Top5=74.51%, LR=0.000294\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:41<00:00,  1.44s/it]\n 21%|██        | 41/195 [01:00<04:04,  1.59s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 29] Step 5500: Loss=2.7175, Top1=58.40%, Top5=71.48%, LR=0.000294\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 141/195 [03:24<01:25,  1.57s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 29] Step 5600: Loss=2.6818, Top1=59.57%, Top5=73.44%, LR=0.000294\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:41<00:00,  1.45s/it]\n 23%|██▎       | 45/195 [01:04<03:27,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 30] Step 5700: Loss=2.5088, Top1=62.01%, Top5=75.88%, LR=0.000293\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 145/195 [03:29<01:03,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 30] Step 5800: Loss=2.5141, Top1=62.79%, Top5=75.29%, LR=0.000293\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [04:41<00:00,  1.44s/it]\n 26%|██▌       | 51/195 [01:19<03:59,  1.66s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 31] Step 5900: Loss=2.5972, Top1=60.25%, Top5=74.71%, LR=0.000292\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 151/195 [03:58<01:01,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 31] Step 6000: Loss=2.6893, Top1=58.59%, Top5=74.80%, LR=0.000292\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:07<00:00,  1.58s/it]\n 29%|██▊       | 56/195 [01:28<03:11,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 32] Step 6100: Loss=2.5609, Top1=62.79%, Top5=74.41%, LR=0.000291\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▉  | 155/195 [04:03<01:05,  1.65s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 32] Step 6200: Loss=2.5429, Top1=63.28%, Top5=75.49%, LR=0.000291\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:06<00:00,  1.57s/it]\n 31%|███▏      | 61/195 [01:37<04:01,  1.80s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 33] Step 6300: Loss=2.4865, Top1=61.82%, Top5=76.56%, LR=0.000291\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 161/195 [04:13<01:00,  1.77s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 33] Step 6400: Loss=2.7383, Top1=58.79%, Top5=72.95%, LR=0.000291\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:07<00:00,  1.58s/it]\n 34%|███▍      | 66/195 [01:46<03:01,  1.41s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 34] Step 6500: Loss=2.5055, Top1=62.40%, Top5=76.07%, LR=0.000290\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 166/195 [04:28<00:43,  1.52s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 34] Step 6600: Loss=2.5832, Top1=60.84%, Top5=74.80%, LR=0.000290\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:15<00:00,  1.62s/it]\n 36%|███▋      | 71/195 [01:55<03:45,  1.82s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 35] Step 6700: Loss=2.6745, Top1=56.64%, Top5=73.24%, LR=0.000289\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 171/195 [04:49<00:45,  1.91s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 35] Step 6800: Loss=2.5588, Top1=61.43%, Top5=77.64%, LR=0.000289\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:31<00:00,  1.70s/it]\n 38%|███▊      | 75/195 [02:16<04:00,  2.00s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 36] Step 6900: Loss=2.4215, Top1=64.26%, Top5=78.03%, LR=0.000288\n","output_type":"stream"},{"name":"stderr","text":" 90%|████████▉ | 175/195 [05:14<00:37,  1.89s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 36] Step 7000: Loss=2.3660, Top1=65.82%, Top5=80.66%, LR=0.000288\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:49<00:00,  1.79s/it]\n 42%|████▏     | 81/195 [02:23<03:46,  1.99s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 37] Step 7100: Loss=2.5058, Top1=62.40%, Top5=77.05%, LR=0.000287\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 181/195 [05:16<00:26,  1.87s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 37] Step 7200: Loss=2.5311, Top1=62.89%, Top5=73.93%, LR=0.000287\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:40<00:00,  1.75s/it]\n 44%|████▍     | 86/195 [02:30<02:46,  1.53s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 38] Step 7300: Loss=2.4395, Top1=63.77%, Top5=77.25%, LR=0.000286\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 186/195 [05:27<00:13,  1.54s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 38] Step 7400: Loss=2.4415, Top1=62.21%, Top5=78.61%, LR=0.000286\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:47<00:00,  1.78s/it]\n 47%|████▋     | 91/195 [02:41<03:26,  1.98s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 39] Step 7500: Loss=2.4800, Top1=62.60%, Top5=76.37%, LR=0.000285\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 191/195 [05:26<00:07,  1.94s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 39] Step 7600: Loss=2.4533, Top1=64.16%, Top5=77.93%, LR=0.000285\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:32<00:00,  1.71s/it]\n 49%|████▉     | 96/195 [02:47<02:28,  1.50s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 40] Step 7700: Loss=2.4868, Top1=63.28%, Top5=76.56%, LR=0.000284\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:41<00:00,  1.75s/it]\n  1%|          | 1/195 [00:03<12:48,  3.96s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 41] Step 7800: Loss=2.4636, Top1=64.55%, Top5=77.34%, LR=0.000283\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 101/195 [02:59<03:05,  1.97s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 41] Step 7900: Loss=2.4442, Top1=63.28%, Top5=76.66%, LR=0.000283\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:41<00:00,  1.75s/it]\n  3%|▎         | 6/195 [00:11<04:56,  1.57s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 42] Step 8000: Loss=2.5878, Top1=61.52%, Top5=74.12%, LR=0.000282\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 105/195 [03:05<02:41,  1.80s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 42] Step 8100: Loss=2.3624, Top1=66.02%, Top5=78.81%, LR=0.000282\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:42<00:00,  1.76s/it]\n  6%|▌         | 11/195 [00:21<05:53,  1.92s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 43] Step 8200: Loss=2.4829, Top1=63.96%, Top5=76.66%, LR=0.000281\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▋    | 110/195 [03:11<02:05,  1.48s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 43] Step 8300: Loss=2.3645, Top1=67.48%, Top5=79.00%, LR=0.000281\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:39<00:00,  1.74s/it]\n  8%|▊         | 16/195 [00:29<04:36,  1.55s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 44] Step 8400: Loss=2.3315, Top1=66.41%, Top5=79.30%, LR=0.000279\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 116/195 [03:22<01:58,  1.49s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 44] Step 8500: Loss=2.3386, Top1=66.50%, Top5=80.27%, LR=0.000279\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:40<00:00,  1.75s/it]\n 11%|█         | 21/195 [00:38<05:35,  1.93s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 45] Step 8600: Loss=2.5119, Top1=64.65%, Top5=78.61%, LR=0.000278\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 121/195 [03:31<02:25,  1.96s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 45] Step 8700: Loss=2.4020, Top1=63.96%, Top5=77.93%, LR=0.000278\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:39<00:00,  1.74s/it]\n 13%|█▎        | 26/195 [00:45<04:19,  1.53s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 46] Step 8800: Loss=2.3326, Top1=66.02%, Top5=80.76%, LR=0.000277\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▍   | 126/195 [03:40<01:46,  1.55s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 46] Step 8900: Loss=2.3035, Top1=66.89%, Top5=79.10%, LR=0.000277\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:40<00:00,  1.75s/it]\n 16%|█▌        | 31/195 [00:55<05:21,  1.96s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 47] Step 9000: Loss=2.3648, Top1=65.33%, Top5=79.00%, LR=0.000275\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 131/195 [03:54<02:11,  2.06s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 47] Step 9100: Loss=2.4155, Top1=66.21%, Top5=79.00%, LR=0.000275\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:55<00:00,  1.82s/it]\n 18%|█▊        | 36/195 [01:03<04:10,  1.58s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 48] Step 9200: Loss=2.4775, Top1=64.36%, Top5=78.52%, LR=0.000274\n","output_type":"stream"},{"name":"stderr","text":" 70%|██████▉   | 136/195 [03:57<01:31,  1.56s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 48] Step 9300: Loss=2.4570, Top1=64.06%, Top5=76.27%, LR=0.000274\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:39<00:00,  1.74s/it]\n 21%|██        | 41/195 [01:12<04:48,  1.87s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 49] Step 9400: Loss=2.3629, Top1=64.16%, Top5=78.22%, LR=0.000273\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 141/195 [04:05<01:43,  1.91s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 49] Step 9500: Loss=2.3908, Top1=66.89%, Top5=79.49%, LR=0.000273\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:38<00:00,  1.74s/it]\n 24%|██▎       | 46/195 [01:19<03:40,  1.48s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 50] Step 9600: Loss=2.5125, Top1=61.72%, Top5=74.80%, LR=0.000271\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 145/195 [04:10<01:38,  1.96s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 50] Step 9700: Loss=2.2665, Top1=67.77%, Top5=80.76%, LR=0.000271\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 195/195 [05:38<00:00,  1.74s/it]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!ls -l /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T22:27:49.443213Z","iopub.execute_input":"2025-08-02T22:27:49.443523Z","iopub.status.idle":"2025-08-02T22:27:49.577227Z","shell.execute_reply.started":"2025-08-02T22:27:49.443497Z","shell.execute_reply":"2025-08-02T22:27:49.576542Z"}},"outputs":[{"name":"stdout","text":"total 0\n","output_type":"stream"}],"execution_count":6}]}