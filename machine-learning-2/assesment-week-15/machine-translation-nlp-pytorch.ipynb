{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12842872,"sourceType":"datasetVersion","datasetId":8122693}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Machine Translation - NLP - Pytorch ","metadata":{}},{"cell_type":"code","source":"import os\nfrom tokenizers import ByteLevelBPETokenizer\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:37:18.533493Z","iopub.execute_input":"2025-08-23T07:37:18.533680Z","iopub.status.idle":"2025-08-23T07:37:19.855346Z","shell.execute_reply.started":"2025-08-23T07:37:18.533653Z","shell.execute_reply":"2025-08-23T07:37:19.854431Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data_path = '/kaggle/input/en-id-dataset/ind.txt'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:37:40.290142Z","iopub.execute_input":"2025-08-23T07:37:40.290438Z","iopub.status.idle":"2025-08-23T07:37:40.293975Z","shell.execute_reply.started":"2025-08-23T07:37:40.290411Z","shell.execute_reply":"2025-08-23T07:37:40.293250Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Load & Bersihkan Dataset","metadata":{}},{"cell_type":"code","source":"en_sents = []\nid_sents = []\n\ntry:\n    with open(data_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            # Pisahkan berdasarkan tab dan ambil dua elemen pertama\n            parts = line.strip().split('\\t')\n            if len(parts) >= 2:\n                en_sents.append(parts[0])\n                id_sents.append(parts[1])\nexcept FileNotFoundError:\n    print(f\"Error: File tidak ditemukan di path '{data_path}'\")\n    print(\"Pastikan path dataset sudah benar.\")\n    # Hentikan eksekusi jika file tidak ada\n    exit()\n\n\nprint(f\"Total pasangan kalimat: {len(en_sents)}\")\nprint(\"\\nContoh data:\")\nfor i in range(5):\n    print(f\"EN: {en_sents[i]}\")\n    print(f\"ID: {id_sents[i]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:38:25.896843Z","iopub.execute_input":"2025-08-23T07:38:25.897568Z","iopub.status.idle":"2025-08-23T07:38:25.953593Z","shell.execute_reply.started":"2025-08-23T07:38:25.897542Z","shell.execute_reply":"2025-08-23T07:38:25.952965Z"}},"outputs":[{"name":"stdout","text":"Total pasangan kalimat: 14881\n\nContoh data:\nEN: Hi.\nID: Hai.\nEN: Run!\nID: Lari!\nEN: Run.\nID: Lari!\nEN: Who?\nID: Siapa?\nEN: Wow!\nID: Wow!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Latih Tokenizer Subward","metadata":{}},{"cell_type":"code","source":"output_dir = 'tokenizers'\nos.makedirs(output_dir, exist_ok=True)\n\n# Ukuran vocabulary\nVOCAB_SIZE = 16000 \nMIN_FREQUENCY = 2\n\n# Tokenizer Bahasa Inggris\nen_tokenizer = ByteLevelBPETokenizer()\nen_tokenizer.train_from_iterator(en_sents, vocab_size=VOCAB_SIZE, min_frequency=MIN_FREQUENCY, special_tokens=[\n    \"<s>\",\n    \"<pad>\",\n    \"</s>\",\n    \"<unk>\",\n    \"<mask>\",\n])\nen_tokenizer.save_model(output_dir, \"en\")\n\n# Tokenizer Bahasa Indonesia\nid_tokenizer = ByteLevelBPETokenizer()\nid_tokenizer.train_from_iterator(id_sents, vocab_size=VOCAB_SIZE, min_frequency=MIN_FREQUENCY, special_tokens=[\n    \"<s>\",\n    \"<pad>\",\n    \"</s>\",\n    \"<unk>\",\n    \"<mask>\",\n])\nid_tokenizer.save_model(output_dir, \"id\")\n\nprint(f\"\\nTokenizer dilatih dan disimpan di '{output_dir}'.\")\nprint(f\"Ukuran Vocab: {VOCAB_SIZE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:39:52.435502Z","iopub.execute_input":"2025-08-23T07:39:52.436063Z","iopub.status.idle":"2025-08-23T07:39:52.966145Z","shell.execute_reply.started":"2025-08-23T07:39:52.436041Z","shell.execute_reply":"2025-08-23T07:39:52.965408Z"}},"outputs":[{"name":"stdout","text":"\n\n\n\n\n\n\nTokenizer dilatih dan disimpan di 'tokenizers'.\nUkuran Vocab: 16000\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Bagi Data Menjadi Train, Validation & Test Set  ","metadata":{}},{"cell_type":"code","source":"# pisah kadi data latih dan temp set (validasi + uji)\ntrain_en, temp_en, train_id, temp_id = train_test_split(\n    en_sents, id_sents, test_size=0.2, random_state=42\n)\n\n# pisah temp set jadi validasi dan uji\nval_en, test_en, val_id, test_id = train_test_split(\n    temp_en, temp_id, test_size=0.5, random_state=42\n)\n\nprint(f\"\\nData berhasil dibagi:\")\nprint(f\"Ukuran set Latih: {len(train_en)}\")\nprint(f\"Ukuran set Validasi: {len(val_en)}\")\nprint(f\"Ukuran set Uji: {len(test_en)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:42:35.398262Z","iopub.execute_input":"2025-08-23T07:42:35.398975Z","iopub.status.idle":"2025-08-23T07:42:35.415018Z","shell.execute_reply.started":"2025-08-23T07:42:35.398949Z","shell.execute_reply":"2025-08-23T07:42:35.414181Z"}},"outputs":[{"name":"stdout","text":"\nData berhasil dibagi:\nUkuran set Latih: 11904\nUkuran set Validasi: 1488\nUkuran set Uji: 1489\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Simpan Data","metadata":{}},{"cell_type":"code","source":"data_dir = 'data_split'\nos.makedirs(data_dir, exist_ok=True)\n\ndef save_sents(sents, file_path):\n    with open(file_path, 'w', encoding='utf-8') as f:\n        for sent in sents:\n            f.write(sent + '\\n')\n\nsave_sents(train_en, os.path.join(data_dir, 'train.en'))\nsave_sents(train_id, os.path.join(data_dir, 'train.id'))\nsave_sents(val_en, os.path.join(data_dir, 'val.en'))\nsave_sents(val_id, os.path.join(data_dir, 'val.id'))\nsave_sents(test_en, os.path.join(data_dir, 'test.en'))\nsave_sents(test_id, os.path.join(data_dir, 'test.id'))\n\nprint(f\"\\nData yang sudah dibagi disimpan di direktori '{data_dir}'.\")\nprint(\"\\nTahap persiapan data selesai!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:42:57.946485Z","iopub.execute_input":"2025-08-23T07:42:57.946759Z","iopub.status.idle":"2025-08-23T07:42:57.963051Z","shell.execute_reply.started":"2025-08-23T07:42:57.946739Z","shell.execute_reply":"2025-08-23T07:42:57.962443Z"}},"outputs":[{"name":"stdout","text":"\nData yang sudah dibagi disimpan di direktori 'data_split'.\n\nTahap persiapan data selesai!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import BPE\nimport os\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:57:44.475645Z","iopub.execute_input":"2025-08-23T07:57:44.476490Z","iopub.status.idle":"2025-08-23T07:57:44.480227Z","shell.execute_reply.started":"2025-08-23T07:57:44.476462Z","shell.execute_reply":"2025-08-23T07:57:44.479440Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# setup device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:57:45.918118Z","iopub.execute_input":"2025-08-23T07:57:45.918670Z","iopub.status.idle":"2025-08-23T07:57:45.923156Z","shell.execute_reply.started":"2025-08-23T07:57:45.918648Z","shell.execute_reply":"2025-08-23T07:57:45.922288Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## Tokenizer","metadata":{}},{"cell_type":"code","source":"# kongifurasi & hyperparameter\nTOKENIZER_DIR = 'tokenizers'\nDATA_DIR = 'data_split'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:57:47.397407Z","iopub.execute_input":"2025-08-23T07:57:47.397692Z","iopub.status.idle":"2025-08-23T07:57:47.401255Z","shell.execute_reply.started":"2025-08-23T07:57:47.397673Z","shell.execute_reply":"2025-08-23T07:57:47.400717Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# English tokenizer\nen_tokenizer = Tokenizer(BPE(\n    vocab=os.path.join(TOKENIZER_DIR, \"en-vocab.json\"),\n    merges=os.path.join(TOKENIZER_DIR, \"en-merges.txt\")\n))\nen_tokenizer.save(os.path.join(TOKENIZER_DIR, \"en-tokenizer.json\"))\n\n# Indonesian tokenizer\nid_tokenizer = Tokenizer(BPE(\n    vocab=os.path.join(TOKENIZER_DIR, \"id-vocab.json\"),\n    merges=os.path.join(TOKENIZER_DIR, \"id-merges.txt\")\n))\nen_tokenizer.save(os.path.join(TOKENIZER_DIR, \"en-tokenizer.json\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:57:49.196164Z","iopub.execute_input":"2025-08-23T07:57:49.196861Z","iopub.status.idle":"2025-08-23T07:57:49.223978Z","shell.execute_reply.started":"2025-08-23T07:57:49.196836Z","shell.execute_reply":"2025-08-23T07:57:49.223229Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/4187326951.py:2: DeprecationWarning: Deprecated in 0.9.0: BPE.__init__ will not create from files anymore, try `BPE.from_file` instead\n  en_tokenizer = Tokenizer(BPE(\n/tmp/ipykernel_36/4187326951.py:9: DeprecationWarning: Deprecated in 0.9.0: BPE.__init__ will not create from files anymore, try `BPE.from_file` instead\n  id_tokenizer = Tokenizer(BPE(\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Hyperparameters\nINPUT_DIM = 16000   # Ukuran vocab EN \nOUTPUT_DIM = 16000  # Ukuran vocab ID \nENC_EMB_DIM = 256\nDEC_EMB_DIM = 256\nENC_HID_DIM = 512\nDEC_HID_DIM = 512\nENC_DROPOUT = 0.5\nDEC_DROPOUT = 0.5\nBATCH_SIZE = 128","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:46:33.594393Z","iopub.execute_input":"2025-08-23T07:46:33.595059Z","iopub.status.idle":"2025-08-23T07:46:33.598987Z","shell.execute_reply.started":"2025-08-23T07:46:33.595033Z","shell.execute_reply":"2025-08-23T07:46:33.598317Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# load tokenizer\nen_tokenizer = Tokenizer.from_file(os.path.join(TOKENIZER_DIR, \"en-tokenizer.json\"))\nid_tokenizer = Tokenizer.from_file(os.path.join(TOKENIZER_DIR, \"id-tokenizer.json\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:58:25.948580Z","iopub.execute_input":"2025-08-23T07:58:25.948891Z","iopub.status.idle":"2025-08-23T07:58:25.979572Z","shell.execute_reply.started":"2025-08-23T07:58:25.948870Z","shell.execute_reply":"2025-08-23T07:58:25.978864Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# get id token spesial\nSRC_PAD_IDX = en_tokenizer.token_to_id('<pad>')\nTRG_PAD_IDX = id_tokenizer.token_to_id('<pad>')\nTRG_SOS_IDX = id_tokenizer.token_to_id('<s>')\nTRG_EOS_IDX = id_tokenizer.token_to_id('</s>')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T07:59:12.629796Z","iopub.execute_input":"2025-08-23T07:59:12.630069Z","iopub.status.idle":"2025-08-23T07:59:12.634155Z","shell.execute_reply.started":"2025-08-23T07:59:12.630051Z","shell.execute_reply":"2025-08-23T07:59:12.633438Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"## Dataset Class","metadata":{}},{"cell_type":"code","source":"class TranslationDataset(Dataset):\n    def __init__(self, data_dir, lang_pair='en-id', split='train'):\n        self.src_sents = self._load_sentences(os.path.join(data_dir, f'{split}.{lang_pair.split(\"-\")[0]}'))\n        self.trg_sents = self._load_sentences(os.path.join(data_dir, f'{split}.{lang_pair.split(\"-\")[1]}'))\n\n    def _load_sentences(self, file_path):\n        with open(file_path, 'r', encoding='utf-8') as f:\n            return [line.strip() for line in f]\n\n    def __len__(self):\n        return len(self.src_sents)\n\n    def __getitem__(self, idx):\n        return self.src_sents[idx], self.trg_sents[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:01:11.924927Z","iopub.execute_input":"2025-08-23T08:01:11.925506Z","iopub.status.idle":"2025-08-23T08:01:11.930655Z","shell.execute_reply.started":"2025-08-23T08:01:11.925484Z","shell.execute_reply":"2025-08-23T08:01:11.929852Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"## Definisikan Function Collate Untuk Data Loader","metadata":{}},{"cell_type":"code","source":"def collate_fn(batch, src_tokenizer, trg_tokenizer, src_pad_idx, trg_pad_idx, trg_sos_idx, trg_eos_idx, device):\n    src_batch, trg_batch = [], []\n    for src_sample, trg_sample in batch:\n        src_batch.append(torch.tensor(src_tokenizer.encode(src_sample).ids, dtype=torch.long))\n        trg_batch.append(torch.tensor([trg_sos_idx] + trg_tokenizer.encode(trg_sample).ids + [trg_eos_idx], dtype=torch.long))\n\n    # Pad sequences\n    src_padded = nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=src_pad_idx)\n    trg_padded = nn.utils.rnn.pad_sequence(trg_batch, batch_first=True, padding_value=trg_pad_idx)\n\n    return src_padded.to(device), trg_padded.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:01:33.117344Z","iopub.execute_input":"2025-08-23T08:01:33.117628Z","iopub.status.idle":"2025-08-23T08:01:33.122909Z","shell.execute_reply.started":"2025-08-23T08:01:33.117606Z","shell.execute_reply":"2025-08-23T08:01:33.122266Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## Arsitektur Model","metadata":{}},{"cell_type":"code","source":"# Encoderr\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim)\n        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, src):\n        # src = [src_len, batch_size]\n        embedded = self.dropout(self.embedding(src))\n        # embedded = [src_len, batch_size, emb_dim]\n        outputs, hidden = self.rnn(embedded)\n        # outputs = [src_len, batch_size, hid_dim * num_directions]\n        # hidden = [n_layers * num_directions, batch_size, hid_dim]\n        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n        # hidden = [batch_size, dec_hid_dim]\n        return outputs, hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:02:06.367870Z","iopub.execute_input":"2025-08-23T08:02:06.368416Z","iopub.status.idle":"2025-08-23T08:02:06.373393Z","shell.execute_reply.started":"2025-08-23T08:02:06.368390Z","shell.execute_reply":"2025-08-23T08:02:06.372805Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# ATTENTION\nclass Attention(nn.Module):\n    def __init__(self, enc_hid_dim, dec_hid_dim):\n        super().__init__()\n        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n\n    def forward(self, hidden, encoder_outputs):\n        # hidden = [batch_size, dec_hid_dim]\n        # encoder_outputs = [src_len, batch_size, enc_hid_dim * 2]\n        batch_size = encoder_outputs.shape[1]\n        src_len = encoder_outputs.shape[0]\n        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n        # hidden = [batch_size, src_len, dec_hid_dim]\n        # encoder_outputs = [batch_size, src_len, enc_hid_dim * 2]\n        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2)))\n        # energy = [batch_size, src_len, dec_hid_dim]\n        attention = self.v(energy).squeeze(2)\n        # attention = [batch_size, src_len]\n        return torch.softmax(attention, dim=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:02:17.255969Z","iopub.execute_input":"2025-08-23T08:02:17.256523Z","iopub.status.idle":"2025-08-23T08:02:17.261984Z","shell.execute_reply.started":"2025-08-23T08:02:17.256496Z","shell.execute_reply":"2025-08-23T08:02:17.261203Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"# DECODER\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n        super().__init__()\n        self.output_dim = output_dim\n        self.attention = attention\n        self.embedding = nn.Embedding(output_dim, emb_dim)\n        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input, hidden, encoder_outputs):\n        # input = [batch_size]\n        # hidden = [batch_size, dec_hid_dim]\n        # encoder_outputs = [src_len, batch_size, enc_hid_dim * 2]\n        input = input.unsqueeze(0)\n        # input = [1, batch_size]\n        embedded = self.dropout(self.embedding(input))\n        # embedded = [1, batch_size, emb_dim]\n        a = self.attention(hidden, encoder_outputs)\n        # a = [batch_size, src_len]\n        a = a.unsqueeze(1)\n        # a = [batch_size, 1, src_len]\n        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n        # encoder_outputs = [batch_size, src_len, enc_hid_dim * 2]\n        weighted = torch.bmm(a, encoder_outputs)\n        # weighted = [batch_size, 1, enc_hid_dim * 2]\n        weighted = weighted.permute(1, 0, 2)\n        # weighted = [1, batch_size, enc_hid_dim * 2]\n        rnn_input = torch.cat((embedded, weighted), dim = 2)\n        # rnn_input = [1, batch_size, (enc_hid_dim * 2) + emb_dim]\n        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n        # output = [1, batch_size, dec_hid_dim]\n        # hidden = [1, batch_size, dec_hid_dim]\n        embedded = embedded.squeeze(0)\n        output = output.squeeze(0)\n        weighted = weighted.squeeze(0)\n        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n        # prediction = [batch_size, output_dim]\n        return prediction, hidden.squeeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:02:24.523615Z","iopub.execute_input":"2025-08-23T08:02:24.524216Z","iopub.status.idle":"2025-08-23T08:02:24.531463Z","shell.execute_reply.started":"2025-08-23T08:02:24.524192Z","shell.execute_reply":"2025-08-23T08:02:24.530628Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# SEQ2SEQ WRAPPER\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n\n    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n        # src = [src_len, batch_size]\n        # trg = [trg_len, batch_size]\n        batch_size = src.shape[1]\n        trg_len = trg.shape[0]\n        trg_vocab_size = self.decoder.output_dim\n        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n        encoder_outputs, hidden = self.encoder(src)\n        input = trg[0,:]\n        for t in range(1, trg_len):\n            output, hidden = self.decoder(input, hidden, encoder_outputs)\n            outputs[t] = output\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            input = trg[t] if teacher_force else top1\n        return outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:02:39.742898Z","iopub.execute_input":"2025-08-23T08:02:39.743132Z","iopub.status.idle":"2025-08-23T08:02:39.749403Z","shell.execute_reply.started":"2025-08-23T08:02:39.743117Z","shell.execute_reply":"2025-08-23T08:02:39.748625Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"## Inisialisasi Model $ Training Komponen","metadata":{}},{"cell_type":"code","source":"# Buat instance model\nattn = Attention(ENC_HID_DIM, DEC_HID_DIM)\nenc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\ndec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\nmodel = Seq2Seq(enc, dec, device).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:03:17.439848Z","iopub.execute_input":"2025-08-23T08:03:17.440114Z","iopub.status.idle":"2025-08-23T08:03:18.128427Z","shell.execute_reply.started":"2025-08-23T08:03:17.440095Z","shell.execute_reply":"2025-08-23T08:03:18.127853Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Inisialisasi weights\ndef init_weights(m):\n    for name, param in m.named_parameters():\n        if 'weight' in name:\n            nn.init.normal_(param.data, mean=0, std=0.01)\n        else:\n            nn.init.constant_(param.data, 0)\nmodel.apply(init_weights) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:03:27.111341Z","iopub.execute_input":"2025-08-23T08:03:27.111695Z","iopub.status.idle":"2025-08-23T08:03:27.200485Z","shell.execute_reply.started":"2025-08-23T08:03:27.111668Z","shell.execute_reply":"2025-08-23T08:03:27.199900Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"Seq2Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(16000, 256)\n    (rnn): GRU(256, 512, bidirectional=True)\n    (fc): Linear(in_features=1024, out_features=512, bias=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Decoder(\n    (attention): Attention(\n      (attn): Linear(in_features=1536, out_features=512, bias=True)\n      (v): Linear(in_features=512, out_features=1, bias=False)\n    )\n    (embedding): Embedding(16000, 256)\n    (rnn): GRU(1280, 512)\n    (fc_out): Linear(in_features=1792, out_features=16000, bias=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n)"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"# Optimizer\noptimizer = optim.Adam(model.parameters())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:03:39.216077Z","iopub.execute_input":"2025-08-23T08:03:39.216675Z","iopub.status.idle":"2025-08-23T08:03:41.720354Z","shell.execute_reply.started":"2025-08-23T08:03:39.216650Z","shell.execute_reply":"2025-08-23T08:03:41.719764Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Loss function\ncriterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:03:46.128142Z","iopub.execute_input":"2025-08-23T08:03:46.128554Z","iopub.status.idle":"2025-08-23T08:03:46.132082Z","shell.execute_reply.started":"2025-08-23T08:03:46.128533Z","shell.execute_reply":"2025-08-23T08:03:46.131318Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# DataLoader\ntrain_dataset = TranslationDataset(DATA_DIR, split='train')\nvalid_dataset = TranslationDataset(DATA_DIR, split='val')\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n                              collate_fn=lambda b: collate_fn(b, en_tokenizer, id_tokenizer, SRC_PAD_IDX, TRG_PAD_IDX, TRG_SOS_IDX, TRG_EOS_IDX, device))\nvalid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False,\n                              collate_fn=lambda b: collate_fn(b, en_tokenizer, id_tokenizer, SRC_PAD_IDX, TRG_PAD_IDX, TRG_SOS_IDX, TRG_EOS_IDX, device))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:04:08.713047Z","iopub.execute_input":"2025-08-23T08:04:08.713634Z","iopub.status.idle":"2025-08-23T08:04:08.725278Z","shell.execute_reply.started":"2025-08-23T08:04:08.713610Z","shell.execute_reply":"2025-08-23T08:04:08.724717Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"print(\"\\nModel, Optimizer, Loss Function, dan DataLoaders berhasil dibuat.\")\nprint(f'Model memiliki {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameter yang dapat dilatih.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:04:28.537850Z","iopub.execute_input":"2025-08-23T08:04:28.538675Z","iopub.status.idle":"2025-08-23T08:04:28.543194Z","shell.execute_reply.started":"2025-08-23T08:04:28.538647Z","shell.execute_reply":"2025-08-23T08:04:28.542298Z"}},"outputs":[{"name":"stdout","text":"\nModel, Optimizer, Loss Function, dan DataLoaders berhasil dibuat.\nModel memiliki 43,313,280 parameter yang dapat dilatih.\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"# tes ambil 1 batch dari train dataloader\nsrc, trg = next(iter(train_dataloader))\nprint(f\"\\nContoh ukuran batch sumber (source): {src.shape}\")\nprint(f\"Contoh ukuran batch target: {trg.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:04:56.550535Z","iopub.execute_input":"2025-08-23T08:04:56.550807Z","iopub.status.idle":"2025-08-23T08:04:56.574213Z","shell.execute_reply.started":"2025-08-23T08:04:56.550788Z","shell.execute_reply":"2025-08-23T08:04:56.573674Z"}},"outputs":[{"name":"stdout","text":"\nContoh ukuran batch sumber (source): torch.Size([128, 34])\nContoh ukuran batch target: torch.Size([128, 32])\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"import torch.optim as optim\nfrom tqdm import tqdm\nimport time\nimport math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:07:04.242154Z","iopub.execute_input":"2025-08-23T08:07:04.242820Z","iopub.status.idle":"2025-08-23T08:07:04.246444Z","shell.execute_reply.started":"2025-08-23T08:07:04.242795Z","shell.execute_reply":"2025-08-23T08:07:04.245610Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# fungsi training\ndef train(model, iterator, optimizer, criterion, clip):\n    model.train()\n    epoch_loss = 0\n    \n    # Menggunakan tqdm untuk progress bar\n    for i, batch in enumerate(tqdm(iterator, desc=\"Training\")):\n        src, trg = batch\n        \n        # Transpose batch karena model RNN/GRU di PyTorch\n        # secara default mengharapkan input: [seq_len, batch_size]\n        src = src.permute(1, 0)\n        trg = trg.permute(1, 0)\n        \n        optimizer.zero_grad()\n        \n        output = model(src, trg)\n        \n        # trg = [trg_len, batch_size]\n        # output = [trg_len, batch_size, output_dim]\n        \n        output_dim = output.shape[-1]\n        \n        # Reshape output dan target untuk loss function\n        # Abaikan token <sos> di awal\n        output = output[1:].reshape(-1, output_dim)\n        trg = trg[1:].reshape(-1)\n        \n        loss = criterion(output, trg)\n        loss.backward()\n        \n        # Mencegah 'exploding gradients'\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        \n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        \n    return epoch_loss / len(iterator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:10:50.951186Z","iopub.execute_input":"2025-08-23T08:10:50.951564Z","iopub.status.idle":"2025-08-23T08:10:50.956995Z","shell.execute_reply.started":"2025-08-23T08:10:50.951539Z","shell.execute_reply":"2025-08-23T08:10:50.956147Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"# fungsi evaluasi\ndef evaluate(model, iterator, criterion):\n    model.eval()\n    epoch_loss = 0\n    \n    with torch.no_grad():\n        for i, batch in enumerate(tqdm(iterator, desc=\"Evaluating\")):\n            src, trg = batch\n            src = src.permute(1, 0)\n            trg = trg.permute(1, 0)\n\n            # Matikan teacher forcing untuk evaluasi\n            output = model(src, trg, 0) \n            \n            output_dim = output.shape[-1]\n            \n            output = output[1:].reshape(-1, output_dim)\n            trg = trg[1:].reshape(-1)\n\n            loss = criterion(output, trg)\n            \n            epoch_loss += loss.item()\n            \n    return epoch_loss / len(iterator)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:10:52.730499Z","iopub.execute_input":"2025-08-23T08:10:52.730768Z","iopub.status.idle":"2025-08-23T08:10:52.735964Z","shell.execute_reply.started":"2025-08-23T08:10:52.730748Z","shell.execute_reply":"2025-08-23T08:10:52.735160Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# helper function untuk menghitung waktu\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:10:55.194872Z","iopub.execute_input":"2025-08-23T08:10:55.195351Z","iopub.status.idle":"2025-08-23T08:10:55.199026Z","shell.execute_reply.started":"2025-08-23T08:10:55.195329Z","shell.execute_reply":"2025-08-23T08:10:55.198388Z"}},"outputs":[],"execution_count":68},{"cell_type":"markdown","source":"## Training Main Loop","metadata":{}},{"cell_type":"code","source":"N_EPOCHS = 10\nCLIP = 1\n\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):\n    \n    start_time = time.time()\n    \n    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n    valid_loss = evaluate(model, valid_dataloader, criterion)\n    \n    end_time = time.time()\n    \n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    # Simpan model jika validation loss membaik\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'baseline-rnn-model.pt')\n    \n    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n\nprint(\"\\nTraining selesai!\")\nprint(f\"Model terbaik disimpan sebagai 'baseline-rnn-model.pt' dengan validation loss: {best_valid_loss:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:10:56.654869Z","iopub.execute_input":"2025-08-23T08:10:56.655131Z","iopub.status.idle":"2025-08-23T08:19:45.226387Z","shell.execute_reply.started":"2025-08-23T08:10:56.655110Z","shell.execute_reply":"2025-08-23T08:19:45.225540Z"}},"outputs":[{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:49<00:00,  1.87it/s]\nEvaluating: 100%|██████████| 12/12 [00:03<00:00,  3.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 01 | Time: 0m 53s\n\tTrain Loss: 5.668 | Train PPL: 289.582\n\t Val. Loss: 5.209 |  Val. PPL: 182.890\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:49<00:00,  1.88it/s]\nEvaluating: 100%|██████████| 12/12 [00:03<00:00,  3.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 02 | Time: 0m 52s\n\tTrain Loss: 4.833 | Train PPL: 125.621\n\t Val. Loss: 5.267 |  Val. PPL: 193.824\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:49<00:00,  1.88it/s]\nEvaluating: 100%|██████████| 12/12 [00:03<00:00,  3.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 03 | Time: 0m 52s\n\tTrain Loss: 4.520 | Train PPL:  91.863\n\t Val. Loss: 5.013 |  Val. PPL: 150.367\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:48<00:00,  1.90it/s]\nEvaluating: 100%|██████████| 12/12 [00:03<00:00,  3.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 04 | Time: 0m 52s\n\tTrain Loss: 4.267 | Train PPL:  71.301\n\t Val. Loss: 4.956 |  Val. PPL: 142.091\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:48<00:00,  1.92it/s]\nEvaluating: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 05 | Time: 0m 51s\n\tTrain Loss: 4.082 | Train PPL:  59.287\n\t Val. Loss: 4.847 |  Val. PPL: 127.372\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:48<00:00,  1.92it/s]\nEvaluating: 100%|██████████| 12/12 [00:03<00:00,  3.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 06 | Time: 0m 51s\n\tTrain Loss: 3.885 | Train PPL:  48.648\n\t Val. Loss: 4.794 |  Val. PPL: 120.792\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:49<00:00,  1.89it/s]\nEvaluating: 100%|██████████| 12/12 [00:03<00:00,  3.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 07 | Time: 0m 52s\n\tTrain Loss: 3.693 | Train PPL:  40.147\n\t Val. Loss: 4.681 |  Val. PPL: 107.827\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:48<00:00,  1.91it/s]\nEvaluating: 100%|██████████| 12/12 [00:03<00:00,  3.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 08 | Time: 0m 52s\n\tTrain Loss: 3.503 | Train PPL:  33.208\n\t Val. Loss: 4.612 |  Val. PPL: 100.678\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:48<00:00,  1.93it/s]\nEvaluating: 100%|██████████| 12/12 [00:03<00:00,  3.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 09 | Time: 0m 51s\n\tTrain Loss: 3.301 | Train PPL:  27.127\n\t Val. Loss: 4.578 |  Val. PPL:  97.289\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:50<00:00,  1.85it/s]\nEvaluating: 100%|██████████| 12/12 [00:03<00:00,  3.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10 | Time: 0m 53s\n\tTrain Loss: 3.055 | Train PPL:  21.229\n\t Val. Loss: 4.482 |  Val. PPL:  88.442\n\nTraining selesai!\nModel terbaik disimpan sebagai 'baseline-rnn-model.pt' dengan validation loss: 4.482\n","output_type":"stream"}],"execution_count":69},{"cell_type":"markdown","source":"## Import Module SacreBLEU ","metadata":{}},{"cell_type":"code","source":"!pip install sacrebleu\n\nimport spacy\nfrom tqdm import tqdm\nimport sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:41:36.616284Z","iopub.execute_input":"2025-08-23T08:41:36.616920Z","iopub.status.idle":"2025-08-23T08:41:41.070073Z","shell.execute_reply.started":"2025-08-23T08:41:36.616897Z","shell.execute_reply":"2025-08-23T08:41:41.069247Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m592.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.2.0 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"# laod model\nmodel.load_state_dict(torch.load('baseline-rnn-model.pt'))\nprint(\"Model 'baseline-rnn-model.pt' berhasil dimuat.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:43:47.070838Z","iopub.execute_input":"2025-08-23T08:43:47.071877Z","iopub.status.idle":"2025-08-23T08:43:47.231847Z","shell.execute_reply.started":"2025-08-23T08:43:47.071848Z","shell.execute_reply":"2025-08-23T08:43:47.231197Z"}},"outputs":[{"name":"stdout","text":"Model 'baseline-rnn-model.pt' berhasil dimuat.\n","output_type":"stream"}],"execution_count":73},{"cell_type":"markdown","source":"## Fungsi Terjemahan","metadata":{}},{"cell_type":"code","source":"def translate_sentence(sentence, src_tokenizer, trg_tokenizer, model, device, max_len=50):\n    model.eval()\n\n    # Tokenisasi kalimat sumber\n    src_tokens = src_tokenizer.encode(sentence.lower()).ids\n    src_tensor = torch.LongTensor(src_tokens).unsqueeze(1).to(device) # [src_len, 1]\n\n    with torch.no_grad():\n        encoder_outputs, hidden = model.encoder(src_tensor)\n\n    # Dapatkan token <sos> dan <eos> dari tokenizer target\n    trg_sos_idx = trg_tokenizer.token_to_id('<s>')\n    trg_eos_idx = trg_tokenizer.token_to_id('</s>')\n    \n    # Mulai output dengan token <sos>\n    trg_indexes = [trg_sos_idx]\n\n    for i in range(max_len):\n        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n        \n        with torch.no_grad():\n            output, hidden = model.decoder(trg_tensor, hidden, encoder_outputs)\n        \n        pred_token = output.argmax(1).item()\n        trg_indexes.append(pred_token)\n\n        if pred_token == trg_eos_idx:\n            break\n    \n    # Konversi kembali dari index ke token\n    trg_tokens = trg_tokenizer.decode(trg_indexes, skip_special_tokens=True)\n    \n    return trg_tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:44:10.672169Z","iopub.execute_input":"2025-08-23T08:44:10.672469Z","iopub.status.idle":"2025-08-23T08:44:10.678635Z","shell.execute_reply.started":"2025-08-23T08:44:10.672447Z","shell.execute_reply":"2025-08-23T08:44:10.677835Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"# fungsi evaluasi kuantiatif dengan SacreBLEU\ndef calculate_bleu(dataset, src_tokenizer, trg_tokenizer, model, device):\n    trgs = []\n    preds = []\n    \n    for src_sent, trg_sent in tqdm(dataset, desc=\"Calculating BLEU\"):\n        pred_trg = translate_sentence(src_sent, src_tokenizer, trg_tokenizer, model, device)\n        \n        preds.append(pred_trg)\n        trgs.append(trg_sent)\n        \n    # Sacrebleu mengharapkan list of references, kita bungkus dalam list tambahan\n    bleu = sacrebleu.corpus_bleu(preds, [trgs])\n    \n    return bleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:44:46.207817Z","iopub.execute_input":"2025-08-23T08:44:46.208512Z","iopub.status.idle":"2025-08-23T08:44:46.212829Z","shell.execute_reply.started":"2025-08-23T08:44:46.208487Z","shell.execute_reply":"2025-08-23T08:44:46.212186Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"# load dataset \ntest_dataset = TranslationDataset(DATA_DIR, split='test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:45:03.335558Z","iopub.execute_input":"2025-08-23T08:45:03.336230Z","iopub.status.idle":"2025-08-23T08:45:03.340780Z","shell.execute_reply.started":"2025-08-23T08:45:03.336206Z","shell.execute_reply":"2025-08-23T08:45:03.340213Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"# hitung score bleu\nbleu_score = calculate_bleu(test_dataset, en_tokenizer, id_tokenizer, model, device)\nprint(f'\\nBLEU score on test set = {bleu_score.score:.2f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:45:15.967673Z","iopub.execute_input":"2025-08-23T08:45:15.967903Z","iopub.status.idle":"2025-08-23T08:45:35.103255Z","shell.execute_reply.started":"2025-08-23T08:45:15.967887Z","shell.execute_reply":"2025-08-23T08:45:35.102513Z"}},"outputs":[{"name":"stderr","text":"Calculating BLEU: 100%|██████████| 1489/1489 [00:18<00:00, 78.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nBLEU score on test set = 0.07\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"# fungsi evaluasi kualitatif \ndef show_random_examples(dataset, num_examples=5):\n    model.eval()\n    \n    print(\"\\n--- Contoh Hasil Terjemahan ---\")\n    for _ in range(num_examples):\n        src, trg = random.choice(dataset)\n        \n        translated_sentence = translate_sentence(src, en_tokenizer, id_tokenizer, model, device)\n        \n        print(f\"\\nSumber (EN)      : {src}\")\n        print(f\"Target (ID)      : {trg}\")\n        print(f\"Prediksi Model   : {translated_sentence}\")\n\nvalid_dataset = TranslationDataset(DATA_DIR, split='val')\nshow_random_examples(valid_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:47:52.000853Z","iopub.execute_input":"2025-08-23T08:47:52.001333Z","iopub.status.idle":"2025-08-23T08:47:52.078310Z","shell.execute_reply.started":"2025-08-23T08:47:52.001309Z","shell.execute_reply":"2025-08-23T08:47:52.077680Z"}},"outputs":[{"name":"stdout","text":"\n--- Contoh Hasil Terjemahan ---\n\nSumber (EN)      : Are you talking to me?\nTarget (ID)      : Apakah kau sedang bicara padaku?\nPrediksi Model   : <s> Kamu m el ihat b el ihat b erapa ? </s>\n\nSumber (EN)      : I won't go there anymore.\nTarget (ID)      : Aku tidak akan pergi ke sana lagi.\nPrediksi Model   : <s> Di at idak akan m em akai p ad anya . </s>\n\nSumber (EN)      : Tom saw Mary eating an apple.\nTarget (ID)      : Tom melihat Mary memakan apel.\nPrediksi Model   : <s> Izinkan m em buat m em buat m em buat m em buat m em buat m em buat k enal . </s>\n\nSumber (EN)      : You're not the only one who's hungry.\nTarget (ID)      : Bukan hanya kamu saja yang merasa lapar.\nPrediksi Model   : <s> Kamu s idak m eng h ar us m el ajar b agi . </s>\n\nSumber (EN)      : What have you got?\nTarget (ID)      : Kalian punya apa?\nPrediksi Model   : <s> Kamu m anak amu akan k amu ? </s>\n","output_type":"stream"}],"execution_count":81},{"cell_type":"markdown","source":"## Arsitektur Model","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, emb_dim, dropout, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        pe = torch.zeros(max_len, emb_dim)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, emb_dim, 2).float() * (-math.log(10000.0) / emb_dim))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:x.size(0), :]\n        return self.dropout(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:50:50.282214Z","iopub.execute_input":"2025-08-23T08:50:50.282549Z","iopub.status.idle":"2025-08-23T08:50:50.289450Z","shell.execute_reply.started":"2025-08-23T08:50:50.282527Z","shell.execute_reply":"2025-08-23T08:50:50.288259Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, \n                 src_vocab_size, \n                 trg_vocab_size, \n                 src_pad_idx, \n                 trg_pad_idx,\n                 emb_dim=256, \n                 nhead=8, \n                 num_encoder_layers=3,\n                 num_decoder_layers=3, \n                 dim_feedforward=512, \n                 dropout=0.1,\n                 device='cpu'):\n        super().__init__()\n\n        self.device = device\n        self.src_tok_emb = nn.Embedding(src_vocab_size, emb_dim)\n        self.trg_tok_emb = nn.Embedding(trg_vocab_size, emb_dim)\n        self.positional_encoding = PositionalEncoding(emb_dim, dropout)\n        \n        # PyTorch sudah menyediakan implementasi Transformer standar\n        self.transformer = nn.Transformer(d_model=emb_dim,\n                                          nhead=nhead,\n                                          num_encoder_layers=num_encoder_layers,\n                                          num_decoder_layers=num_decoder_layers,\n                                          dim_feedforward=dim_feedforward,\n                                          dropout=dropout,\n                                          batch_first=False) # Kita set False agar sesuai dengan RNN\n        \n        self.generator = nn.Linear(emb_dim, trg_vocab_size)\n        self.src_pad_idx = src_pad_idx\n        self.trg_pad_idx = trg_pad_idx\n\n    def _generate_square_subsequent_mask(self, sz):\n        mask = (torch.triu(torch.ones(sz, sz, device=self.device)) == 1).transpose(0, 1)\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n\n    def _create_padding_mask(self, pad_idx, sequence):\n        return (sequence == pad_idx).transpose(0, 1)\n\n    def forward(self, src, trg):\n        # src: [src_len, batch_size]\n        # trg: [trg_len, batch_size]\n\n        src_seq_len = src.shape[0]\n        trg_seq_len = trg.shape[0]\n\n        src_padding_mask = self._create_padding_mask(self.src_pad_idx, src)\n        trg_padding_mask = self._create_padding_mask(self.trg_pad_idx, trg)\n\n        trg_mask = self._generate_square_subsequent_mask(trg_seq_len)\n\n        src_emb = self.positional_encoding(self.src_tok_emb(src))\n        trg_emb = self.positional_encoding(self.trg_tok_emb(trg))\n\n        output = self.transformer(src_emb, trg_emb,\n                                  src_mask=None, # Tidak perlu untuk encoder\n                                  tgt_mask=trg_mask,\n                                  memory_mask=None, # Tidak perlu\n                                  src_key_padding_mask=src_padding_mask,\n                                  tgt_key_padding_mask=trg_padding_mask,\n                                  memory_key_padding_mask=src_padding_mask)\n        \n        return self.generator(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:51:07.418844Z","iopub.execute_input":"2025-08-23T08:51:07.419592Z","iopub.status.idle":"2025-08-23T08:51:07.427784Z","shell.execute_reply.started":"2025-08-23T08:51:07.419560Z","shell.execute_reply":"2025-08-23T08:51:07.427068Z"}},"outputs":[],"execution_count":83},{"cell_type":"markdown","source":"## Inisialisai Model, Optimizer, Loss","metadata":{}},{"cell_type":"code","source":"# Hyperparameter\nINPUT_DIM = 16000\nOUTPUT_DIM = 16000\nEMB_DIM = 256\nNHEAD = 8\nFFN_HID_DIM = 512\nNUM_ENCODER_LAYERS = 3\nNUM_DECODER_LAYERS = 3\nDROPOUT = 0.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:52:00.354899Z","iopub.execute_input":"2025-08-23T08:52:00.355628Z","iopub.status.idle":"2025-08-23T08:52:00.359335Z","shell.execute_reply.started":"2025-08-23T08:52:00.355604Z","shell.execute_reply":"2025-08-23T08:52:00.358624Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"# Model\ntransformer_model = Transformer(src_vocab_size=INPUT_DIM,\n                                trg_vocab_size=OUTPUT_DIM,\n                                src_pad_idx=SRC_PAD_IDX,\n                                trg_pad_idx=TRG_PAD_IDX,\n                                emb_dim=EMB_DIM,\n                                nhead=NHEAD,\n                                num_encoder_layers=NUM_ENCODER_LAYERS,\n                                num_decoder_layers=NUM_DECODER_LAYERS,\n                                dim_feedforward=FFN_HID_DIM,\n                                dropout=DROPOUT,\n                                device=device).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:52:17.498746Z","iopub.execute_input":"2025-08-23T08:52:17.499274Z","iopub.status.idle":"2025-08-23T08:52:17.695128Z","shell.execute_reply.started":"2025-08-23T08:52:17.499251Z","shell.execute_reply":"2025-08-23T08:52:17.694433Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"# Weight\ndef initialize_weights(m):\n    if hasattr(m, 'weight') and m.weight.dim() > 1:\n        nn.init.xavier_uniform_(m.weight.data)\ntransformer_model.apply(initialize_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:52:33.435010Z","iopub.execute_input":"2025-08-23T08:52:33.435624Z","iopub.status.idle":"2025-08-23T08:52:33.452005Z","shell.execute_reply.started":"2025-08-23T08:52:33.435600Z","shell.execute_reply":"2025-08-23T08:52:33.451430Z"}},"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"Transformer(\n  (src_tok_emb): Embedding(16000, 256)\n  (trg_tok_emb): Embedding(16000, 256)\n  (positional_encoding): PositionalEncoding(\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (transformer): Transformer(\n    (encoder): TransformerEncoder(\n      (layers): ModuleList(\n        (0-2): 3 x TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n          )\n          (linear1): Linear(in_features=256, out_features=512, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=512, out_features=256, bias=True)\n          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): TransformerDecoder(\n      (layers): ModuleList(\n        (0-2): 3 x TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n          )\n          (multihead_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n          )\n          (linear1): Linear(in_features=256, out_features=512, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=512, out_features=256, bias=True)\n          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n          (dropout3): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (generator): Linear(in_features=256, out_features=16000, bias=True)\n)"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"# optimizer \ntransformer_optimizer = optim.Adam(transformer_model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:52:47.099591Z","iopub.execute_input":"2025-08-23T08:52:47.099878Z","iopub.status.idle":"2025-08-23T08:52:47.104278Z","shell.execute_reply.started":"2025-08-23T08:52:47.099848Z","shell.execute_reply":"2025-08-23T08:52:47.103704Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"# Loss function tetap sama\nprint(\"Model Transformer, Optimizer, dan Loss Function berhasil dibuat.\")\nprint(f'Model memiliki {sum(p.numel() for p in transformer_model.parameters() if p.requires_grad):,} parameter yang dapat dilatih.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:53:14.052040Z","iopub.execute_input":"2025-08-23T08:53:14.052284Z","iopub.status.idle":"2025-08-23T08:53:14.057062Z","shell.execute_reply.started":"2025-08-23T08:53:14.052268Z","shell.execute_reply":"2025-08-23T08:53:14.056229Z"}},"outputs":[{"name":"stdout","text":"Model Transformer, Optimizer, dan Loss Function berhasil dibuat.\nModel memiliki 16,258,688 parameter yang dapat dilatih.\n","output_type":"stream"}],"execution_count":89},{"cell_type":"markdown","source":"## Fungsi Training & Evaluasi Untuk Transformer","metadata":{}},{"cell_type":"code","source":"# fungsi training\ndef train_transformer(model, iterator, optimizer, criterion, clip):\n    model.train()\n    epoch_loss = 0\n    \n    for i, batch in enumerate(tqdm(iterator, desc=\"Training\")):\n        src, trg = batch\n        \n        # Transpose batch agar sesuai dengan input model [seq_len, batch_size]\n        src = src.permute(1, 0)\n        trg = trg.permute(1, 0)\n        \n        optimizer.zero_grad()\n        \n        # Siapkan input dan target untuk decoder\n        # Input tidak menyertakan token <eos> terakhir\n        trg_input = trg[:-1, :]\n        \n        # Model memprediksi berdasarkan src dan trg_input\n        output = model(src, trg_input)\n        \n        output_dim = output.shape[-1]\n        \n        # Reshape output untuk loss function\n        # Target untuk loss tidak menyertakan token <sos> pertama\n        output = output.reshape(-1, output_dim)\n        trg_output = trg[1:, :].reshape(-1)\n        \n        loss = criterion(output, trg_output)\n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        \n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        \n    return epoch_loss / len(iterator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:58:02.828459Z","iopub.execute_input":"2025-08-23T08:58:02.829133Z","iopub.status.idle":"2025-08-23T08:58:02.834652Z","shell.execute_reply.started":"2025-08-23T08:58:02.829109Z","shell.execute_reply":"2025-08-23T08:58:02.833919Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"def evaluate_transformer(model, iterator, criterion):\n    model.eval()\n    epoch_loss = 0\n    \n    with torch.no_grad():\n        for i, batch in enumerate(tqdm(iterator, desc=\"Evaluating\")):\n            src, trg = batch\n            src = src.permute(1, 0)\n            trg = trg.permute(1, 0)\n\n            trg_input = trg[:-1, :]\n            \n            output = model(src, trg_input)\n            \n            output_dim = output.shape[-1]\n            \n            output = output.reshape(-1, output_dim)\n            trg_output = trg[1:, :].reshape(-1)\n\n            loss = criterion(output, trg_output)\n            \n            epoch_loss += loss.item()\n            \n    return epoch_loss / len(iterator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:58:05.013229Z","iopub.execute_input":"2025-08-23T08:58:05.013726Z","iopub.status.idle":"2025-08-23T08:58:05.018610Z","shell.execute_reply.started":"2025-08-23T08:58:05.013703Z","shell.execute_reply":"2025-08-23T08:58:05.017849Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"# fungsi helper untuk hitung waktu\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:58:06.477282Z","iopub.execute_input":"2025-08-23T08:58:06.477987Z","iopub.status.idle":"2025-08-23T08:58:06.481572Z","shell.execute_reply.started":"2025-08-23T08:58:06.477960Z","shell.execute_reply":"2025-08-23T08:58:06.480830Z"}},"outputs":[],"execution_count":98},{"cell_type":"markdown","source":"## Training Loop Utama","metadata":{}},{"cell_type":"code","source":"N_EPOCHS = 15\nCLIP = 1\n\nbest_valid_loss = float('inf')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:58:08.253306Z","iopub.execute_input":"2025-08-23T08:58:08.253857Z","iopub.status.idle":"2025-08-23T08:58:08.257216Z","shell.execute_reply.started":"2025-08-23T08:58:08.253832Z","shell.execute_reply":"2025-08-23T08:58:08.256685Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"for epoch in range(N_EPOCHS):\n    \n    start_time = time.time()\n    \n    # Gunakan model dan optimizer Transformer\n    train_loss = train_transformer(transformer_model, train_dataloader, transformer_optimizer, criterion, CLIP)\n    valid_loss = evaluate_transformer(transformer_model, valid_dataloader, criterion)\n    \n    end_time = time.time()\n    \n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    # Simpan model jika validation loss membaik\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(transformer_model.state_dict(), 'transformer-model.pt')\n    \n    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n\nprint(\"\\nTraining Transformer selesai!\")\nprint(f\"Model terbaik disimpan sebagai 'transformer-model.pt' dengan validation loss: {best_valid_loss:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T08:58:09.466426Z","iopub.execute_input":"2025-08-23T08:58:09.466948Z","iopub.status.idle":"2025-08-23T08:59:49.021183Z","shell.execute_reply.started":"2025-08-23T08:58:09.466925Z","shell.execute_reply":"2025-08-23T08:59:49.020347Z"}},"outputs":[{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.01it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 41.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 01 | Time: 0m 6s\n\tTrain Loss: 7.899 | Train PPL: 2695.223\n\t Val. Loss: 6.434 |  Val. PPL: 622.452\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.12it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 41.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 02 | Time: 0m 6s\n\tTrain Loss: 5.861 | Train PPL: 351.058\n\t Val. Loss: 5.507 |  Val. PPL: 246.397\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.02it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 39.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 03 | Time: 0m 6s\n\tTrain Loss: 5.359 | Train PPL: 212.479\n\t Val. Loss: 5.248 |  Val. PPL: 190.145\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.23it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 39.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 04 | Time: 0m 6s\n\tTrain Loss: 5.136 | Train PPL: 170.028\n\t Val. Loss: 5.019 |  Val. PPL: 151.196\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.27it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 40.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 05 | Time: 0m 6s\n\tTrain Loss: 4.956 | Train PPL: 141.989\n\t Val. Loss: 4.921 |  Val. PPL: 137.147\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.21it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 40.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 06 | Time: 0m 6s\n\tTrain Loss: 4.871 | Train PPL: 130.469\n\t Val. Loss: 4.852 |  Val. PPL: 127.998\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 14.94it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 41.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 07 | Time: 0m 6s\n\tTrain Loss: 4.797 | Train PPL: 121.100\n\t Val. Loss: 4.768 |  Val. PPL: 117.688\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.21it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 40.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 08 | Time: 0m 6s\n\tTrain Loss: 4.698 | Train PPL: 109.781\n\t Val. Loss: 4.664 |  Val. PPL: 106.033\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.04it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 41.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 09 | Time: 0m 6s\n\tTrain Loss: 4.601 | Train PPL:  99.595\n\t Val. Loss: 4.584 |  Val. PPL:  97.877\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.28it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 41.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10 | Time: 0m 6s\n\tTrain Loss: 4.520 | Train PPL:  91.854\n\t Val. Loss: 4.521 |  Val. PPL:  91.946\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.04it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 41.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 11 | Time: 0m 6s\n\tTrain Loss: 4.455 | Train PPL:  86.016\n\t Val. Loss: 4.467 |  Val. PPL:  87.122\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.14it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 40.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 12 | Time: 0m 6s\n\tTrain Loss: 4.393 | Train PPL:  80.896\n\t Val. Loss: 4.416 |  Val. PPL:  82.765\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.04it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 39.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 13 | Time: 0m 6s\n\tTrain Loss: 4.334 | Train PPL:  76.232\n\t Val. Loss: 4.337 |  Val. PPL:  76.511\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.14it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 41.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 14 | Time: 0m 6s\n\tTrain Loss: 4.272 | Train PPL:  71.688\n\t Val. Loss: 4.285 |  Val. PPL:  72.627\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:06<00:00, 15.06it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 41.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 15 | Time: 0m 6s\n\tTrain Loss: 4.208 | Train PPL:  67.207\n\t Val. Loss: 4.213 |  Val. PPL:  67.586\n\nTraining Transformer selesai!\nModel terbaik disimpan sebagai 'transformer-model.pt' dengan validation loss: 4.213\n","output_type":"stream"}],"execution_count":100},{"cell_type":"markdown","source":"## Load Model Transformasi Terbaik","metadata":{}},{"cell_type":"code","source":"transformer_model.load_state_dict(torch.load('transformer-model.pt'))\nprint(\"Model Transformer terbaik 'transformer-model.pt' berhasil dimuat.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:01:23.630683Z","iopub.execute_input":"2025-08-23T09:01:23.630944Z","iopub.status.idle":"2025-08-23T09:01:23.691546Z","shell.execute_reply.started":"2025-08-23T09:01:23.630927Z","shell.execute_reply":"2025-08-23T09:01:23.690857Z"}},"outputs":[{"name":"stdout","text":"Model Transformer terbaik 'transformer-model.pt' berhasil dimuat.\n","output_type":"stream"}],"execution_count":101},{"cell_type":"markdown","source":"## Fungsi Terjemahan Untuk Transform","metadata":{}},{"cell_type":"code","source":"def translate_sentence_transformer(sentence, src_tokenizer, trg_tokenizer, model, device, max_len=50):\n    model.eval()\n\n    # Tokenisasi kalimat sumber\n    src_tokens = src_tokenizer.encode(sentence.lower()).ids\n    src_tensor = torch.LongTensor(src_tokens).unsqueeze(1).to(device) # [src_len, 1]\n\n    # Buat padding mask untuk source\n    src_padding_mask = model._create_padding_mask(model.src_pad_idx, src_tensor)\n\n    with torch.no_grad():\n        # Encoder memproses seluruh kalimat sumber sekali\n        memory = model.transformer.encoder(model.positional_encoding(model.src_tok_emb(src_tensor)), \n                                            src_key_padding_mask=src_padding_mask)\n    \n    # Dapatkan token <sos> dan <eos>\n    trg_sos_idx = trg_tokenizer.token_to_id('<s>')\n    trg_eos_idx = trg_tokenizer.token_to_id('</s>')\n    \n    # Mulai output dengan token <sos>\n    trg_indexes = [trg_sos_idx]\n\n    for i in range(max_len):\n        # Buat tensor dari output sejauh ini\n        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(1).to(device) # [trg_len, 1]\n        \n        # Buat subsequent mask untuk target\n        trg_mask = model._generate_square_subsequent_mask(trg_tensor.size(0))\n\n        with torch.no_grad():\n            # Decoder memprediksi token berikutnya\n            output = model.transformer.decoder(model.positional_encoding(model.trg_tok_emb(trg_tensor)), \n                                               memory, \n                                               tgt_mask=trg_mask)\n            \n            # Ambil prediksi dari token terakhir saja\n            pred = model.generator(output[-1, :, :])\n        \n        pred_token = pred.argmax(1).item()\n        trg_indexes.append(pred_token)\n\n        if pred_token == trg_eos_idx:\n            break\n    \n    # Konversi kembali dari index ke token\n    trg_tokens = trg_tokenizer.decode(trg_indexes, skip_special_tokens=True)\n    \n    return trg_tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:02:54.607383Z","iopub.execute_input":"2025-08-23T09:02:54.608121Z","iopub.status.idle":"2025-08-23T09:02:54.614582Z","shell.execute_reply.started":"2025-08-23T09:02:54.608097Z","shell.execute_reply":"2025-08-23T09:02:54.613895Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"# fungsi calculate\ndef calculate_bleu_transformer(dataset, src_tokenizer, trg_tokenizer, model, device):\n    trgs = []\n    preds = []\n    \n    for src_sent, trg_sent in tqdm(dataset, desc=\"Calculating BLEU\"):\n        pred_trg = translate_sentence_transformer(src_sent, src_tokenizer, trg_tokenizer, model, device)\n        \n        preds.append(pred_trg)\n        trgs.append(trg_sent)\n        \n    bleu = sacrebleu.corpus_bleu(preds, [trgs])\n    \n    return bleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:03:08.266107Z","iopub.execute_input":"2025-08-23T09:03:08.266677Z","iopub.status.idle":"2025-08-23T09:03:08.271012Z","shell.execute_reply.started":"2025-08-23T09:03:08.266653Z","shell.execute_reply":"2025-08-23T09:03:08.270172Z"}},"outputs":[],"execution_count":103},{"cell_type":"code","source":"# Muat data uji\ntest_dataset = TranslationDataset(DATA_DIR, split='test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:03:57.361037Z","iopub.execute_input":"2025-08-23T09:03:57.361766Z","iopub.status.idle":"2025-08-23T09:03:57.366261Z","shell.execute_reply.started":"2025-08-23T09:03:57.361738Z","shell.execute_reply":"2025-08-23T09:03:57.365633Z"}},"outputs":[],"execution_count":104},{"cell_type":"code","source":"# Hitung skor BLEU\nbleu_score_transformer = calculate_bleu_transformer(test_dataset, en_tokenizer, id_tokenizer, transformer_model, device)\nprint(f'\\nBLEU score (Transformer) on test set = {bleu_score_transformer.score:.2f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:04:05.896465Z","iopub.execute_input":"2025-08-23T09:04:05.897176Z","iopub.status.idle":"2025-08-23T09:05:11.097800Z","shell.execute_reply.started":"2025-08-23T09:04:05.897152Z","shell.execute_reply":"2025-08-23T09:05:11.097123Z"}},"outputs":[{"name":"stderr","text":"Calculating BLEU: 100%|██████████| 1489/1489 [01:05<00:00, 22.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nBLEU score (Transformer) on test set = 0.01\n","output_type":"stream"}],"execution_count":105},{"cell_type":"markdown","source":"## Evaluasi Kualitatif","metadata":{}},{"cell_type":"code","source":"def show_random_examples_transformer(dataset, num_examples=5):\n    print(\"\\n--- Contoh Hasil Terjemahan (Transformer) ---\")\n    for _ in range(num_examples):\n        src, trg = random.choice(dataset)\n        \n        translated_sentence = translate_sentence_transformer(src, en_tokenizer, id_tokenizer, transformer_model, device)\n        \n        print(f\"\\nSumber (EN)      : {src}\")\n        print(f\"Target (ID)      : {trg}\")\n        print(f\"Prediksi Model   : {translated_sentence}\")\n\n# Ambil dari data validasi\nvalid_dataset = TranslationDataset(DATA_DIR, split='val')\nshow_random_examples_transformer(valid_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:05:13.307066Z","iopub.execute_input":"2025-08-23T09:05:13.307338Z","iopub.status.idle":"2025-08-23T09:05:13.538264Z","shell.execute_reply.started":"2025-08-23T09:05:13.307316Z","shell.execute_reply":"2025-08-23T09:05:13.537690Z"}},"outputs":[{"name":"stdout","text":"\n--- Contoh Hasil Terjemahan (Transformer) ---\n\nSumber (EN)      : Tom isn't afraid of death.\nTarget (ID)      : Tom tidak takut mati.\nPrediksi Model   : <s> Aku t idak m emb el akukan m ang m ang . </s>\n\nSumber (EN)      : A horse is an animal.\nTarget (ID)      : Kuda adalah binatang.\nPrediksi Model   : <s> Itu m ang m ang m ang . </s>\n\nSumber (EN)      : I have no knife to cut with.\nTarget (ID)      : Aku tidak punya pisau untuk memotongnya.\nPrediksi Model   : <s> Di it amu m ang m ang m ang m ang . </s>\n\nSumber (EN)      : You must start soon.\nTarget (ID)      : Kamu harus mulai secepatnya.\nPrediksi Model   : <s> Di ak amu m ang m ang m ang m ang . </s>\n\nSumber (EN)      : Tom sat down on the sand next to Mary.\nTarget (ID)      : Tom duduk di atas pasir di sebelah Mary.\nPrediksi Model   : <s> Aku t idak m emb el akukan m ang m ang m ang m ang m ang . </s>\n","output_type":"stream"}],"execution_count":106},{"cell_type":"markdown","source":"## Ablation Study","metadata":{}},{"cell_type":"code","source":"# jumlah parameter sama, jumlah layer berbeda\nABLATED_NUM_LAYERS = 1\n\nablated_model = Transformer(src_vocab_size=INPUT_DIM,\n                            trg_vocab_size=OUTPUT_DIM,\n                            src_pad_idx=SRC_PAD_IDX,\n                            trg_pad_idx=TRG_PAD_IDX,\n                            emb_dim=EMB_DIM,\n                            nhead=NHEAD,\n                            # Perubahan utama ada di sini\n                            num_encoder_layers=ABLATED_NUM_LAYERS,\n                            num_decoder_layers=ABLATED_NUM_LAYERS,\n                            dim_feedforward=FFN_HID_DIM,\n                            dropout=DROPOUT,\n                            device=device).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:13:56.271745Z","iopub.execute_input":"2025-08-23T09:13:56.272334Z","iopub.status.idle":"2025-08-23T09:13:56.389674Z","shell.execute_reply.started":"2025-08-23T09:13:56.272309Z","shell.execute_reply":"2025-08-23T09:13:56.388911Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"# Inisialisasi weights\nablated_model.apply(initialize_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:14:08.708841Z","iopub.execute_input":"2025-08-23T09:14:08.709509Z","iopub.status.idle":"2025-08-23T09:14:08.715553Z","shell.execute_reply.started":"2025-08-23T09:14:08.709487Z","shell.execute_reply":"2025-08-23T09:14:08.714935Z"}},"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"Transformer(\n  (src_tok_emb): Embedding(16000, 256)\n  (trg_tok_emb): Embedding(16000, 256)\n  (positional_encoding): PositionalEncoding(\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (transformer): Transformer(\n    (encoder): TransformerEncoder(\n      (layers): ModuleList(\n        (0): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n          )\n          (linear1): Linear(in_features=256, out_features=512, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=512, out_features=256, bias=True)\n          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): TransformerDecoder(\n      (layers): ModuleList(\n        (0): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n          )\n          (multihead_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n          )\n          (linear1): Linear(in_features=256, out_features=512, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=512, out_features=256, bias=True)\n          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n          (dropout3): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (generator): Linear(in_features=256, out_features=16000, bias=True)\n)"},"metadata":{}}],"execution_count":113},{"cell_type":"code","source":"# optimizer baru\nablated_optimizer = optim.Adam(ablated_model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n\nprint(f'\\nModel Ablated memiliki {sum(p.numel() for p in ablated_model.parameters() if p.requires_grad):,} parameter yang dapat dilatih.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:15:09.397273Z","iopub.execute_input":"2025-08-23T09:15:09.397830Z","iopub.status.idle":"2025-08-23T09:15:09.403125Z","shell.execute_reply.started":"2025-08-23T09:15:09.397789Z","shell.execute_reply":"2025-08-23T09:15:09.402414Z"}},"outputs":[{"name":"stdout","text":"\nModel Ablated memiliki 13,622,912 parameter yang dapat dilatih.\n","output_type":"stream"}],"execution_count":115},{"cell_type":"markdown","source":"## Latih Model Ablated","metadata":{}},{"cell_type":"code","source":"N_EPOCHS = 10 \nCLIP = 1\nbest_ablated_valid_loss = float('inf')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:15:49.182435Z","iopub.execute_input":"2025-08-23T09:15:49.182672Z","iopub.status.idle":"2025-08-23T09:15:49.186165Z","shell.execute_reply.started":"2025-08-23T09:15:49.182656Z","shell.execute_reply":"2025-08-23T09:15:49.185487Z"}},"outputs":[],"execution_count":116},{"cell_type":"code","source":"for epoch in range(N_EPOCHS):\n    start_time = time.time()\n    \n    train_loss = train_transformer(ablated_model, train_dataloader, ablated_optimizer, criterion, CLIP)\n    valid_loss = evaluate_transformer(ablated_model, valid_dataloader, criterion)\n    \n    end_time = time.time()\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    if valid_loss < best_ablated_valid_loss:\n        best_ablated_valid_loss = valid_loss\n        torch.save(ablated_model.state_dict(), 'transformer-ablated-model.pt')\n    \n    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | PPL: {math.exp(train_loss):7.3f}')\n    print(f'\\t Val. Loss: {valid_loss:.3f} | PPL: {math.exp(valid_loss):7.3f}')\n\nprint(\"\\nTraining model ablated selesai!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:15:51.244877Z","iopub.execute_input":"2025-08-23T09:15:51.245453Z","iopub.status.idle":"2025-08-23T09:16:34.548682Z","shell.execute_reply.started":"2025-08-23T09:15:51.245431Z","shell.execute_reply":"2025-08-23T09:16:34.548014Z"}},"outputs":[{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:03<00:00, 23.38it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 56.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 01 | Time: 0m 4s\n\tTrain Loss: 7.960 | PPL: 2864.890\n\t Val. Loss: 6.483 | PPL: 653.662\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:03<00:00, 23.66it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 55.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 02 | Time: 0m 4s\n\tTrain Loss: 5.912 | PPL: 369.345\n\t Val. Loss: 5.549 | PPL: 257.108\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:03<00:00, 23.50it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 54.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 03 | Time: 0m 4s\n\tTrain Loss: 5.407 | PPL: 222.869\n\t Val. Loss: 5.277 | PPL: 195.829\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:03<00:00, 23.38it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 53.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 04 | Time: 0m 4s\n\tTrain Loss: 5.168 | PPL: 175.591\n\t Val. Loss: 5.063 | PPL: 157.987\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:03<00:00, 23.49it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 52.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 05 | Time: 0m 4s\n\tTrain Loss: 4.976 | PPL: 144.830\n\t Val. Loss: 4.933 | PPL: 138.828\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:04<00:00, 23.05it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 55.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 06 | Time: 0m 4s\n\tTrain Loss: 4.880 | PPL: 131.604\n\t Val. Loss: 4.872 | PPL: 130.535\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:03<00:00, 23.68it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 55.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 07 | Time: 0m 4s\n\tTrain Loss: 4.812 | PPL: 122.933\n\t Val. Loss: 4.799 | PPL: 121.399\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:03<00:00, 23.49it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 52.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 08 | Time: 0m 4s\n\tTrain Loss: 4.725 | PPL: 112.757\n\t Val. Loss: 4.695 | PPL: 109.366\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:03<00:00, 23.41it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 55.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 09 | Time: 0m 4s\n\tTrain Loss: 4.610 | PPL: 100.519\n\t Val. Loss: 4.562 | PPL:  95.765\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 93/93 [00:03<00:00, 23.75it/s]\nEvaluating: 100%|██████████| 12/12 [00:00<00:00, 55.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10 | Time: 0m 4s\n\tTrain Loss: 4.495 | PPL:  89.540\n\t Val. Loss: 4.458 | PPL:  86.284\n\nTraining model ablated selesai!\n","output_type":"stream"}],"execution_count":117},{"cell_type":"markdown","source":"## Evaluasi Model Ablated","metadata":{}},{"cell_type":"code","source":"# muat weights terbaik dari model ablated\nablated_model.load_state_dict(torch.load('transformer-ablated-model.pt'))\n\n# htung skor BLEU pada test set\nbleu_score_ablated = calculate_bleu_transformer(test_dataset, en_tokenizer, id_tokenizer, ablated_model, device)\n\nprint(\"\\n--- Hasil Ablation Study ---\")\nprint(f\"Model Transformer Asli (3 layers) -> BLEU Score: {bleu_score_transformer.score:.2f}\")\nprint(f\"Model Transformer Ablated (1 layer) -> BLEU Score: {bleu_score_ablated.score:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T09:16:37.758210Z","iopub.execute_input":"2025-08-23T09:16:37.758503Z","iopub.status.idle":"2025-08-23T09:17:11.156327Z","shell.execute_reply.started":"2025-08-23T09:16:37.758480Z","shell.execute_reply":"2025-08-23T09:17:11.155730Z"}},"outputs":[{"name":"stderr","text":"Calculating BLEU: 100%|██████████| 1489/1489 [00:33<00:00, 44.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n--- Hasil Ablation Study ---\nModel Transformer Asli (3 layers) -> BLEU Score: 0.01\nModel Transformer Ablated (1 layer) -> BLEU Score: 0.01\n","output_type":"stream"}],"execution_count":118}]}